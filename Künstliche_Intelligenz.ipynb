{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01d4a9f6-7e7b-4dbb-abc9-1efb6d03bd0d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Abstract\n",
    "\n",
    "Bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e85d1c-d44b-4c25-b158-6f2905f80d45",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f626ef7-f50e-4496-b020-156d216721b1",
   "metadata": {},
   "source": [
    "# Einleitung\n",
    "\n",
    "Blla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cced1b-26e7-4ad0-ab90-36009e7b6a87",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Neuronale Netzwerke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410ddab-bf4d-4e55-8d7f-1e26fbad42a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Grundlagen\n",
    "\n",
    "Ein neuronales Netzwerk kann in vielerlei Hinsichten mit einem Gehirn verglichen werden. Ähnlich wie das Gehirn besteht ein neuronales Netzwerk aus vielen Neuronen. Es gibt verschiedene Arten von Neuronen, die sich unter anderem durch ihre Aktivierungsfunktionen unterscheiden. Auf Aktivierungsfunktionen wird in einem späteren Teil der Arbeit genauer eingegangen.\n",
    "Grundsätzlich besitzt jedes Neuron Eingabewerte $x_j$ die mit Gewichten (Weights) $w_j$ verbunden sind. Noch dazu besitzt jedes Neuron ein Bias-Wert (Bias) $b$. All diese Faktoren haben Einfluss auf den Ausgabewert $z$ eines Neurons. Um diesen zu berechnen, wird die gewichtete Summe der Eingabewerte mit dem Bias-Wert addiert. (vgl. Nielsen, 2015, #Perceptrons) Mathematisch kann diese Berechnung folgendermaßen dargestellt werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192590f-623f-4907-be77-e0b6612af4c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$z = \\sum_{j=1}^n {w_j x_j + b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cb75a-9bf1-498d-8942-8f7af9a9d576",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Dabei steht $n$ für die Anzahl an Eingabewerten und Gewichten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57355cd4-171e-474c-8f2e-c12eb18b3b63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Mit einem einzelnen Neuron kann nicht viel angefangen werden, deswegen verbindet man die Neuronen miteinander, wodurch ein neuronales Netzwerk entsteht. Es gibt viele verschiedene Arten von neuronalen Netzwerken, das einfachste davon ist das sogenannte \"Feedforward Neural Network\".\n",
    "Bei dieser Variante werden Informationen kontinuierlich, d.h. ausschließlich von einer Schicht zur nächsthöheren, weitergeleitet. Es kann in drei Teile unterteilt werden: die Eingabeschicht, die verborgenen Schichten und die Ausgabeschicht. (ebd.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8818ad7-4195-45da-9add-3aab007ba08f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_input",
     "image"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <figure>\n",
       "            <img style=\"width: 500px;\" src=\"data:image/png;base64,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\" alt=\"Neuronales Netzwerk\">\n",
       "            <figcaption id=\"abb1\" >Abb. 1: Neuronales Netzwerk (Verf.)</figcaption>\n",
       "        </figure>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Zeichne Netzwerk mit Code\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from src.erstelle_netzwerk import zeichne_netzwerk\n",
    "from src.hilfsfunktionen import erstelle_bild\n",
    "\n",
    "grosse = 6\n",
    "y_ratio = 0.5\n",
    "zeichne_netzwerk(grosse, y_ratio, [3, 4, 4, 2])\n",
    "\n",
    "bild = BytesIO()\n",
    "plt.savefig(bild, format=\"png\")\n",
    "bild.seek(0)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "html = erstelle_bild(bild, 500, \"Neuronales Netzwerk\")\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56986517-2d6f-431d-baac-9bf04da86977",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Die Eingabeschicht (Input Layer)\n",
    "\n",
    "Die Eingabeschicht empfängt die Daten von externen Quellen. Bei einem Zahlenerkennungsmodell beispielsweise würde die Eingabeschicht die Pixeldaten des Bildes repräsentieren. Dementsprechend würde ein 28x28-Bild 784 Eingabeneuronen benötigen. (vgl. Lheureux, o.J.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab660d53-68fa-41ec-851e-3c257787b627",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Die verborgenen Schichten (Hidden Layers)\n",
    "\n",
    "Die verborgenen Schichten sind das, was neuronale Netzwerke so besonders macht. Sie verbinden die Eingabeschicht und die Ausgabeschicht miteinander. Je nach Schwierigkeitsgrad der Anwendung werden mehr und längere verborgene Schichten benötigt. Je mehr verborgene Neuronen es gibt, desto kompliziertere Berechnungen kann das neuronale Netzwerk durchführen. (ebd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8239d8d-2a1a-4cd2-ae37-2d1f53d7be2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Ausgabeschicht (Output Layer)\n",
    "\n",
    "Die Ausgabeschicht gibt die endgültigen Vorhersagen des neuronalen Netzwerkes zurück. In dem Zahlenerkennungsmodell wären das die Ziffern null bis neun, wobei jede Ausgabe die Wahrscheinlichkeit für eine der Ziffern darstellt. (ebd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde567cd-3f18-4dc9-be06-0c91c71bae8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Forward Propagation\n",
    "\n",
    "### Matrixmultiplikation\n",
    "\n",
    "Bei der Forward Propagation werden die Eingabewerte des neuronalen Netzwerkes zur nächsten Schicht weitergegeben, bis sie zur Ausgabeschicht kommen und Vorhersagen (Predictions) erzeugen. (vgl. Anshumanm2fja, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6286fbc-d586-4913-8044-64d48f1ed0b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Um das neuronale Netzwerk in der Programmierung umzusetzen, verwende ich die Programmiersprache Python in Kombination mit dem Paket \"NumPy\". Ein neuronales Netzwerk mit zwei Eingabeneuronen und einem Ausgabeneuron kann wie folgt dargestellt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ac96032-d188-4f6e-9ba1-e462c8ab1593",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # Import des Pakets NumPy\n",
    "\n",
    "inputs = np.array([0.3, 0.6]) # Die Eingabewerte der Eingabeneuronen\n",
    "\n",
    "# Die Gewichte zwischen den zwei Eingabeneuronen und dem Ausgabeneuron\n",
    "weights = np.array([0.8, 0.2])\n",
    "bias = 4 # Der Bias-Wert des Ausgabeneurons\n",
    "\n",
    "# Berechnung des Ausgabewerts des Ausgabeneurons\n",
    "output = inputs[0] * weights[0] + inputs[1] * weights[1] + bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa743ec-e182-47fb-897c-cc067a6c6042",
   "metadata": {},
   "source": [
    "In diesem Beispiel sind \"inputs\" die Eingabewerte der Eingabeneuronen und \"weights\" die Gewichtswerte zwischen den Eingabeneuronen und dem Ausgabeneuron. Der Bias-Wert des Ausgabeneurons wird als \"bias\" definiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371846de-0cdf-4309-9989-b39f2a929d92",
   "metadata": {},
   "source": [
    "Mathematisch kann die Liste an Eingabewerten als Zeilenvektor dargestellt werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daf0fe2-c4f3-4b61-9a49-79cb6051f693",
   "metadata": {},
   "source": [
    "$$\n",
    "\\def\\xvector{\\begin{bmatrix}\n",
    "    x_1 & x_2 & \\cdots & x_n\n",
    "\\end{bmatrix}}\n",
    "\\\\\n",
    "\\mathbf{x} = \\xvector$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465618df-2596-46a7-8e63-e4757de06125",
   "metadata": {},
   "source": [
    "Hierbei stellt $n$ die Anzahl der Eingabewerte dar und somit hat der Vektor die Dimension $(1 \\times n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d3784-545c-40a2-b6b2-ab85d7917e4d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Im Folgenden werden auch noch die Ausgaben eines neuronalen Netzwerkes mit zwei Eingabeneuronen und zwei Ausgabeneuronen programmatisch berechnet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bcfc23f-e38f-430c-aa90-1f41a8550266",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.120000000000001 11.84\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([1.2, 3.2])\n",
    "\n",
    "# Gewichte zwischen Eingabeneuronen und Ausgabeneuronen\n",
    "weights1 = np.array([0.8, 1.3])  # Gewichte für das erste Ausgabeneuron\n",
    "weights2 = np.array([3.1, 1.6])  # Gewichte für das zweite Ausgabeneuron\n",
    "\n",
    "bias1 = 4  # Bias-Wert für das erste Ausgabeneuron\n",
    "bias2 = 3  # Bias-Wert für das zweite Ausgabeneuron\n",
    "\n",
    "# Der Ausgabewert des ersten Ausgabeneurons\n",
    "output1 = inputs[0] * weights1[0] + inputs[1] * weights1[1] + bias1\n",
    "\n",
    "# Der Ausgabewert des zweiten Ausgabeneurons\n",
    "output2 = inputs[0] * weights2[0] + inputs[1] * weights2[1] + bias2\n",
    "\n",
    "print(output1, output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b44e45-62bc-480e-b4f1-2b5f335c9e76",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Jedoch ist diese Schreibweise sehr mühsam und ineffizient, weshalb ich zur Berechnung der Ausgaben Vektoren und Matrizen zusammen in Kombination mit der Matrixmultiplikation verwende. Dazu stelle ich die Gewichte als Matrix dar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ed220-e985-4602-9850-257c0348849b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\def\\Wmatrix{\\begin{bmatrix}\n",
    "    w_{1,1} & w_{1,2} & \\cdots & w_{1,k} \\\\\n",
    "    w_{2,1} & w_{2,2} & \\cdots & w_{2,k} \\\\\n",
    "    \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "    w_{n,1} & w_{n,2} & \\cdots & w_{n,k}\n",
    "\\end{bmatrix}}\n",
    "\\\\\n",
    "\\mathbf{W} = \\Wmatrix$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772609f9-eecc-469f-839f-f5dfbe1039f9",
   "metadata": {},
   "source": [
    "Die Gewichtsmatrix $\\mathbf{W}$ hat $n$ Zeilen, die der Anzahl der Eingabeneuronen entsprechen, und $k$ Spalten, die der Anzahl der Ausgabeneuronen entsprechen. Somit hat die Gewichtsmatrix die Form $(n \\times k)$. Das Gewicht $w_{1,2}$ beschreibt die Verbindung zwischen dem ersten Eingabeneuron und dem zweiten Ausgabeneuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0cfe43-e1b7-423f-84bd-35771f693847",
   "metadata": {},
   "source": [
    "Um die Ausgabewerte des neuronalen Netzwerks zu berechnen, verwende ich die Matrixmultiplikation. Damit die Berechnung übersichtlicher wird, vereinfache ich den Eingabevektor $\\mathbf{x}$ und die Gewichtsmatrix $\\mathbf{W}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b516f8b-ab54-4d03-960b-3084d269a9c4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\def\\xvector{\\begin{bmatrix}\n",
    "    x_1 & x_2 & x_3\n",
    "\\end{bmatrix}}\n",
    "\\\\\n",
    "\\def\\Wmatrix{\\begin{bmatrix}\n",
    "    w_{1,1} & w_{1,2} \\\\\n",
    "    w_{2,1} & w_{2,2} \\\\\n",
    "    w_{3,1} & w_{3,2}\n",
    "\\end{bmatrix}}\n",
    "\\\\\n",
    "\\mathbf{x} = \\xvector$$\n",
    "$$\\mathbf{W} = \\Wmatrix$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5cdb1-94f9-448d-bccf-153e447013eb",
   "metadata": {},
   "source": [
    "Hierbei hat der Eingabevektor $\\mathbf{x}$ die Form $(1 \\times 3)$ und der Gewichtsmatrix $\\mathbf{W}$ die Form $(3 \\times 2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c4bca8-1bd2-483e-a54c-3c6fee946acb",
   "metadata": {},
   "source": [
    "Bei der Matrixmultiplikation werden zwei Matrizen miteinander multipliziert, wodurch eine neue Matrix entsteht. Dabei muss die Anzahl der Spalten der ersten Matrix mit der Anzahl der Zeilen der zweiten Matrix übereinstimmen. Das Ergebnis ist eine Matrix, deren Anzahl an Zeilen der ersten Matrix und deren Anzahl an Spalten der zweiten Matrix entspricht. Bei der Berechnung werden die Zeilen der ersten Matrix mit den entsprechenden Spalten der zweiten Matrix multipliziert und die Produkte anschließend summiert. (vgl. Jung, 2014) Diese Rechenoperation kann wie folgt dargestellt werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d6f11c-e345-4321-b189-4fe2a7e9afd7",
   "metadata": {},
   "source": [
    "$$\n",
    "\\def\\xvector{\\begin{bmatrix}\n",
    "    x_1 & x_2 & x_3\n",
    "\\end{bmatrix}}\n",
    "\\\\\n",
    "\\def\\Wmatrix{\\begin{bmatrix}\n",
    "    w_{1,1} & w_{1,2} \\\\\n",
    "    w_{2,1} & w_{2,2} \\\\\n",
    "    w_{3,1} & w_{3,2}\n",
    "\\end{bmatrix}}\n",
    "\\\\\n",
    "\\def\\xWVector{\\begin{bmatrix}\n",
    "    x_1 w_{1,1} + x_2 w_{2,1} + x_3 w_{3,1} & x_1 w_{1,2} + x_2 w_{2,2} + x_3 w_{3,2}\n",
    "\\end{bmatrix}}\n",
    "\\mathbf{x} \\times \\mathbf{W} = \\xvector \\times \\Wmatrix = \\xWVector$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278d0be-49fe-414f-a53c-e11101663d60",
   "metadata": {},
   "source": [
    "Das Ergebnis ist eine Matrix, deren Anzahl an Zeilen der Anzahl der Zeilen von $\\mathbf{x}$ und deren Anzahl an Spalten der Anzahl der Spalten von $\\mathbf{W}$ entspricht. In diesem Fall hat der resultierende Vektor die Form $(1 \\times 2)$, da $\\mathbf{x}$ eine Zeile und $\\mathbf{W}$ zwei Spalten hat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da501c-61f9-4628-80d5-f78b5c61d596",
   "metadata": {},
   "source": [
    "Anschließend wird das Ergebnis mit dem Bias-Vektor $\\mathbf{b}$ der Form $(1 \\times 2)$ addiert, um den Ausgabevektor $\\mathbf{z}$ zu bilden. Die vollständige Formel sieht daher so aus:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd088a-81ef-48ed-9a6a-ce7b07af0ad4",
   "metadata": {},
   "source": [
    "$$\\mathbf{z} = \\mathbf{x} \\times \\mathbf{W} + \\mathbf{b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27300b17-f48f-486e-a9fa-ea20b2588612",
   "metadata": {},
   "source": [
    "Der Python-Code für diese Berechnung lautet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49f22265-dbae-4cf6-bcce-6110e8eaf3a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.12 11.84]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([1.2, 3.2]) # (1 x 2)\n",
    "\n",
    "# Gewichtsmatrix zwischen Eingabeneuronen und Ausgabeneuronen\n",
    "# (4 x 2)\n",
    "weights = np.array([\n",
    "    [0.8, 3.1], # Gewichte zwischen den ersten Eingabeneuron und den Ausgabenneuronen\n",
    "    [1.3, 1.6], # Gewichte zwischen den ersten Eingabeneuron und den Ausgabenneuronen\n",
    "])\n",
    "\n",
    "bias = [4, 3] # Bias-Vektor für die Ausgabeneuronen (1 x 2)\n",
    "\n",
    "# Berechnung der Ausgabewerte durch Matrixmultiplikation\n",
    "outputs = np.dot(inputs, weights) + bias  # Vektor von Ausgabewerten z (1 x 2)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1571cd-67bb-4b1d-ac0f-5c83c2cff956",
   "metadata": {},
   "source": [
    "Hierbei ist \"inputs\" den Eingabevektor $\\mathbf{x}$ und \"weights\" die Gewichtsmatrix $\\mathbf{W}$ zwischen Eingabe- und Ausgabeneuronen dar. \"bias ist der Bias-Vektor $\\mathbf{b}$ der Ausgabeneuronen und \"outputs\" repräsentiert ein Vektor der berechneten Ausgabewerte $\\mathbf{z}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a22ec-8a22-419c-9d4e-82b532bab902",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Batches\n",
    "\n",
    "Bis jetzt rechnet der Code jeweils nur einen Trainingsbeispiel pro Zyklus aus. Um die Effizienz zu steigern, werden jedoch mehrere Trainibgsbeispiele pro Zyklus gleichzeitig verarbeitet. Diese Menge an Trainingsbeispielen wird als \"Batch\" bezeichnet. Die gleichzeitige Bearbeitung mehrerer Beispiele ermöglicht die Parallelisierung von Berechnungen. Das Lernen von neuronalen Netzwerken wird in der Praxis mit GPUs (Graphics Processing Units) durchgeführt. GPUs besitzen eine hohe Anzahl an Prozessoren, wodurch auch aufwendige Berechnungen schnell durchgeführt werden können. Eine weitere essenzielle Eigenschaft von Batches ist die Normalisierung. Wenn mehrere Schichten gleichzeitig ausgeführt werden, kann die Schwankung der Ausgabewerte ausbalanciert werden. Dadurch wird das Lernen stabiler und konsistenter.\n",
    "(vgl. c, 2020, TC: 8:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29575db0-f0cd-4896-81e5-8f7838d55ac8",
   "metadata": {},
   "source": [
    "Mathematisch lässt sich ein Batch von Trainingsbeispielen als eine Matrix $\\mathbf{X}$ darstellen:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab1e2e1-4a7d-46c3-8223-dbd938c4b1c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$\n",
    "\\def\\Xmatrix{\\begin{bmatrix}\n",
    "    x_{1,1} & w_{1,2} & \\cdots & w_{1,n} \\\\\n",
    "    x_{2,1} & w_{2,2} & \\cdots & w_{2,n} \\\\\n",
    "    \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "    x_{m,1} & w_{m,2} & \\cdots & w_{m,n}\n",
    "\\end{bmatrix}}\n",
    "\\\\\n",
    "\\mathbf{X} = \\Xmatrix$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aea81d-cade-49d8-8b4f-3ab8231816e0",
   "metadata": {},
   "source": [
    "Die $\\mathbf{X}$ Matrix hat $n$ Zeilen (die Anzahl der Eingabeneuronen) und $k$ Spalten (die Anzahl der Ausgabeneuronen) und somit die Form $(n \\times k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1a38f4-9cc9-4ab0-bce9-74118c822d57",
   "metadata": {},
   "source": [
    "Die Matrixmultiplikation funktioniert weiterhin. Solange die Spaltenanzahl der Eingabematrix $\\mathbf{X}$ mit der Zeilenanzahl der Gewichtsmatrix $\\mathbf{W}$ übereinstimmt, kann die Berechnung durchgeführt werden. Das Ergebnis ist eine Ausgabematrix $\\mathbf{Z}$ mit der Form $(m \\times k)$, wobei $(m \\times k)$ die Anzahl der Eingabevektoren (Batchgröße) und $k$ die Anzahl der Ausgabeneuronen darstellt. Der zugehörige Code sieht nun folgendermaßen aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c3d2a50c-a2f5-4433-a32e-b88becb33f6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output",
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.12 11.84]\n",
      " [ 8.12 14.84]\n",
      " [ 7.62 16.34]\n",
      " [ 9.34 16.13]]\n"
     ]
    }
   ],
   "source": [
    "# Eingabematrix einer Batch mit 4 Trainingsbeispielen, \n",
    "# wobei jedes Beispiel 2 Eingabewerte enthält (4 x 2)\n",
    "inputs = [\n",
    "    [1.2, 3.2],\n",
    "    [3.2, 1.2],\n",
    "    [4.2, 0.2],\n",
    "    [3.1, 2.2],\n",
    "]\n",
    "\n",
    "# Berechnung der Ausgabewerte durch Matrixmultiplikation\n",
    "outputs = np.dot(inputs, weights) + bias # Matrix von Ausgabewerten (4 x 2)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de80553-b1ba-4a9d-a7f1-b2630483b92c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "source": [
    "Spätere Kapitel benötigen das Wissen um Matrizen zu transponieren.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161bd2b5-dea9-4712-9269-8b9ae7c765d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Die Layer-Klasse\n",
    "\n",
    "Um weitere Schichten hinzuzufügen, kann der bereits vorhandene Code wiederverwendet werden. Um dies effizient umzusetzen, bietet es sich an, Klassen zu schreiben. Die Klasse \"Layer\" dient hier als Bauplan für alle Schichten, die instanziiert werden, in diesem Fall \"hidden_layer\" und \"output_layer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3adccef7-9a8b-48b7-b4d7-9314a56f7d46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07958253 -0.07880953  0.23822111  0.07970762  0.16851563]\n",
      " [ 0.09379458 -0.06170056  0.12922273  0.06033783  0.07366433]\n",
      " [ 0.1009006  -0.05314608  0.07472354  0.05065294  0.02623868]\n",
      " [ 0.0905911  -0.06576194  0.16740408  0.06800869  0.12300217]]\n",
      "[[1.2, 3.2], [3.2, 1.2], [4.2, 0.2], [3.1, 2.2]]\n"
     ]
    }
   ],
   "source": [
    "class Layer:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        \"\"\"\n",
    "        n_inputs: Anzahl an Eingabewerten (bzw. Neuronen der vorherigen Schicht).\n",
    "        n_neurons: Anzahl an Neuronen für diese Schicht.\n",
    "        \"\"\"\n",
    "        self.weights = 0.1 * np.random.randn(n_inputs, n_neurons) # Gewichtsmatrix\n",
    "        self.bias = 0.1 * np.random.randn(1, n_neurons) # Bias-Vektor\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Berechnung des Ausgabewerts für die Neuronen in dieser Schicht basierend\n",
    "        auf den Eingabewerte \"inputs\".\n",
    "        \"\"\"\n",
    "        self.saved_inputs = inputs # Eingabewerte für spätere Verwendung speichern\n",
    "        outputs = np.dot(inputs, self.weights) + self.bias # Ausgabewerte als Matrix\n",
    "        return outputs # Rückgabe der Ausgabewerte\n",
    "\n",
    "# Eingabeschicht mit 2 Neuronen → verborgenen Schicht mit 4 Neuronen\n",
    "hidden_layer = Layer(2, 4)\n",
    "\n",
    "# Verborgenen Schicht mit 4 Neuronen → Ausgabeschicht mit 5 Neuronen\n",
    "output_layer = Layer(4, 5)\n",
    "\n",
    "# Ausgabewerte für die verborgene Schicht\n",
    "hidden_layer_outputs = hidden_layer.forward(inputs)\n",
    "\n",
    "# Ausgabewerte für die Ausgabeschicht\n",
    "output_layer_outputs = output_layer.forward(hidden_layer_outputs)\n",
    "print(output_layer_outputs)\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59b323-2baf-491d-8daf-d05f330686ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die Methode \"forward\" berechnet die Ausgabewerte \"outputs\" anhand der Eingabewerte \"inputs\", der Gewichtsmatrix \"self.weights\" und des Bias-Vektors \"self.bias\" und gibt diese zurück.\n",
    "Die Ausgaben \"hidden_layer_outputs\" der verborgenen Schicht \"hidden_layer\" werden mit den Eingabewerten \"inputs\" aus der Eingabeschicht berechnet. Diese Ausgabewerte dienen als Eingaben für die nächste Schicht, die Ausgabeschicht \"output_layer\", um die \"output_layer_outputs\" zu berechnen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba821825-b5d2-400f-813d-776f048da535",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Regression vs Klassifizierung\n",
    "\n",
    "Für die späteren Kapitel ist es wichtig zwischen Regressions- und Klassifizierungsproblemen zu unterscheiden. Regression ist eine Supervised Learning-Methode. Sie wird verwendet, um kontinuierliche numerische Werte vorherzusagen. Dabei wird eine Beziehung zwischen Eingangsvariablen und Ausgabewerten hergestellt. Typische Anwendungen umfassen zum Beispiel die Vorhersage von Verkaufszahlen, Temperaturen oder Immobilienpreisen. (vgl. Saxena, 2024)\n",
    "\n",
    "Klassifizierung ist ebenfalls eine Supervised Learning-Methode, die darauf abzielt, Eingabedaten in diskrete Kategorien einzuteilen. Typische Anwendungen sind die Bilderkennung oder die Spam-Erkennung. (ebd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f923c40-eca3-4cbf-9ab8-e67b5ab32554",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Activation Functions\n",
    "\n",
    "Ein neuronales Netzwerk ist im Wesentlichen eine Funktionsannäherung. Activation Functions ermöglichen es neuronalen Netzwerken, nicht-lineare Beziehungen zwischen Daten zu modellieren. Ein Neuron ohne Activation Function ist eine lineare Funktion. Besteht ein neuronales Netzwerk nur aus solchen Neuronen, dann kann dieses Netzwerk sich nur an lineare Funktionen annähern und besitzt somit nicht die Fähigkeit, komplexere Funktionen wie eine Sinusfunktion zu approximieren. (vgl. Kinsley, 2020, 7:47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c463cde5-2f60-4f0e-ac8f-37a2604bbbb2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_input",
     "image"
    ]
   },
   "outputs": [],
   "source": [
    "# Zeichne Sinus Funktionsannäherung mit Code\n",
    "\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "from src import sin\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from src.hilfsfunktionen import erstelle_bild\n",
    "import math\n",
    "\n",
    "sin_eingaben = np.arange(-math.pi, math.pi, 0.1)\n",
    "sin_eingaben = sin_eingaben.reshape(len(sin_eingaben), 1)\n",
    "ziele = np.sin(sin_eingaben)\n",
    "\n",
    "netzwerk,_ = sin.trainiere_netzwerk(sin_eingaben, ziele)\n",
    "\n",
    "vorhersagen = netzwerk.vorwaerts_durchlauf(sin_eingaben)\n",
    "plt.plot(sin_eingaben, ziele, label=\"Wahre Funktion\")\n",
    "plt.plot(sin_eingaben, vorhersagen, label=\"Neuronales Netzwerk\", color=\"orange\")\n",
    "\n",
    "bild = BytesIO()\n",
    "plt.savefig(bild, format=\"png\", bbox_inches='tight')\n",
    "bild.seek(0)\n",
    "plt.close()\n",
    "\n",
    "html = erstelle_bild(bild, 400, \"Lineare Funktionsannäherung einer Sinuskurve\")\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec2673-4375-4477-8d11-b1a29a79d35f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Um dieses Problem zu lösen, werden auf das Ergebnis der Neuronen Aktivierungsfunktionen angewendet. Es gibt verschiedene Arten von Aktivierungsfunktionen, zwei weit verbreitete und beliebte sind die Sigmoid Function und ReLU Function (Rectified Linear Unit). (vgl. Kinsley, 2020, TC: 7:52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbd9605-4224-4be8-8e66-886739815e76",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Die Sigmoid Function\n",
    "\n",
    "Die Sigmoid-Funktion ist eine mathematische Funktion, die den Wertebereich auf ein bestimmtes Intervall beschränkt und eine S-förmige Kurve bildet. Es gibt verschiedene Varianten der Sigmoid-Funktion, eine davon ist die logistische Sigmoid-Funktion. Diese Funktion beschränkt den Wertebereich auf das Intervall zwischen null und eins. Im Kontext des maschinellen Lernens wird die logistische Sigmoid-Funktion oft einfach als \"Sigmoid-Funktion\" bezeichnet (vgl. Topper, 2023). Mathematisch lässt sich diese Funktion durch folgende Gleichung darstellen:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0e290e-693c-45bd-91c5-95de4b385c84",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$a_i = \\sigma(z_i) = \\frac{1}{1 +e^{-z_i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34f0f40-660e-48df-880f-4d0362859dc1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Dabei steht $a_i$ für den aktivierten Ausgabewert des $i$-ten Neuron und $z_i$ für den jeweiligen rohen Ausgabewert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d216b2-d8f7-4464-a7d1-c6a165622bc4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Um die Sigmoid Function an Schichten von Neuronen anzuwenden, erstelle ich die Klasse \"Sigmoid\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61126a-f302-4f9d-8ce9-1909f29e1875",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def forward(self, raw_outputs):\n",
    "        \"\"\"\n",
    "        Berechnet die aktivierten Ausgabewerte basierend auf den rohen Ausgabewerten\n",
    "        \"raw_outputs\".\n",
    "        \"\"\"\n",
    "        activated_outputs  = 1 / (1 + np.exp(-raw_outputs))\n",
    "        return activated_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b34fccf-f331-4aa2-9531-72d04dde6eb5",
   "metadata": {},
   "source": [
    "Ähnlich wie bei der Layer-Klasse enthält die Sigmoid-Klasse eine Methode namens \"forward\". Diese berechnet die aktivierten Ausgabewerte \"activated_outputs\" anhand der rohen Ausgabewerte \"raw_outputs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b0c42-de06-4945-891c-3f56d959c487",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "output_layer = Layer(2, 4)\n",
    "activation_function = Sigmoid()\n",
    "\n",
    "raw_outputs = output_layer.forward(inputs)\n",
    "activated_outputs = activation_function.forward(raw_outputs)\n",
    "print(activated_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c7688e-0020-42cb-b938-1663d013d6aa",
   "metadata": {},
   "source": [
    "In diesem Beispiel wird die Methode \"forward\" der Klasse \"Sigmoid\" verwendet, um die aktivierten Ausgabewerte aus den rohen Ausgabewerten der Ausgabeschicht zu berechnen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c546f63d-3e35-4d73-8cde-f514e4e3cc62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Die ReLU Function\n",
    "\n",
    "Eine weitere Activation Function ist die ReLU Function. Der Vorteil der ReLU Function gegenüber anderen Activation Functions ist ihre Effizienz.\n",
    "Ihre Funktionsweise ist einfach: Ist ein Wert positiv, wird der Wert beibehalten, ansonsten wird der Wert gleich 0 gesetzt. (vgl. Kinsley, 2020, TC: 9:00) Die Formel dafür ist:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf5c88-de5c-4ef0-87ec-b1dcc4c4db4d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$a_i=max(0,z_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222e002-a461-4329-944b-c94967030a1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Auch hier erstelle ich die Klasse \"ReLU\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c425b0e-6323-46f0-ba02-0ff720121648",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def forward(self, raw_outputs):\n",
    "        \"\"\"\n",
    "        Berechnet die aktivierten Ausgabewerte basierend auf den rohen Ausgabewerten\n",
    "        \"raw_outputs\".\n",
    "        \"\"\"\n",
    "        self.raw_outputs = raw_outputs\n",
    "        activated_outputs = np.maximum(0, raw_outputs)\n",
    "        return activated_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d50a06-c8ae-4bd8-b3f4-a8087c6366db",
   "metadata": {},
   "source": [
    "In diesem Codeblock werden die rohen Ausgaben \"raw_outputs\" mit der Funktion \"np.maximum\" in aktivierte Ausgaben \"activated_outputs\" umgewandelt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4756aee2-c2b7-4caa-b914-f9655f717572",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Die Softmax Function\n",
    "\n",
    "Die Softmax Function ist eine weitere Aktivierungsfunktion, die aber in der Ausgabeschicht bei Klassifizierungsproblemen durchgeführt wird. Sie transformiert die Rohwerte in Wahrscheinlichkeiten, die zusammen 1 ergeben. Dies ermöglicht es, die Ausgaben des neuronalen Netzwerkes als Wahrscheinlichkeiten für die möglichen Kategorien zu interpretieren. (vgl. Belagatti, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97747e5-5615-4930-87bb-f7eaced619a5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die Softmax Function exponiert die Ausgaben mit Hilfe der exponentiellen Funktion $e^y$. Anschließend werden diese Werte normalisiert in dem sie durch die Summe aller exponierte Werte dividiert werden. (ebd.) Die mathematische Formel sieht dann so aus:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d38c44-9db8-4d31-8c79-ff09a849b4f1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$a_i = \\frac {e^{z_i}} {\\sum_{j=1} {e^{z_j}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9e697a-86b9-4bbc-8019-477788cb02f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "So wie bei der der Sigmoid Function und der ReLU Function erstelle ich auch für die Softmax Function eine Klasse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf69fbb-133b-4ef3-bb57-e10ea0a24de3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def forward(self, raw_outputs):\n",
    "        \"\"\"\n",
    "        Berechnet die aktivierten Ausgabewerte basierend auf den rohen Ausgabewerten\n",
    "        \"raw_outputs\".\n",
    "        \"\"\"\n",
    "        # Exponierte Werte\n",
    "        exponentiated_values = np.exp(raw_outputs - np.max(raw_outputs, axis=1, keepdims=True))\n",
    "        # Summe der exponierten Werte\n",
    "        sum_values = np.sum(exponentiated_values, axis=1, keepdims=True)\n",
    "        # Normalisierte / aktivierte Ausgaben\n",
    "        normalized_outputs  = exponentiated_values / sum_values\n",
    "        return normalized_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c8660-9927-4048-bae1-16f6d360ce6f",
   "metadata": {},
   "source": [
    "In diesem Abschnicht werden zuerst die exponierte Werte \"exponentiated_values\" mit \"np.exp\" berechnet. Anschließend werden diese Werte normalisiert, in dem sie durch die Summe der exponierten Werte \"sum_values\" dividiert werden und somit die aktivierten Ausgaben \"normalized_outputs\" bilden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8af34b0-72c0-4323-9f61-30c655528c61",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Die Netzwerk-Klasse\n",
    "\n",
    "Um die verschiedenen Komponenten des neuronalen Netzwerkes, wie die Schichten und Aktivierungsfunktionen, effizient zu verwalten, erstelle ich die Klasse \"Netzwork\". Diese Klasse besteht aus einer Liste von Schichten \"self.layers\" und einer Liste von Aktivierungsfunktionen \"self.activation_functions\". Zusätzlich enthält sie die Methode \"forward_propagation\". Diese Methode basiert auf den Eingabewerten \"inputs\" der Eingabeschicht und führt eine Forward Propagation durch. Dabei werden schichtweise die rohen Ausgaben jeder Schicht berechnet und dann mit der entsprechenden Aktivierungsfunktion aktiviert. Die endgültigen Ergebnisse in der letzten Schicht sind die Vorhersagen \"predictions\" des neuronalen Netzwerkes und werden zurückgegeben. Mit der Methode \"add_layer\" können Schichten und deren entsprechenden Aktivierungsfunktionen zum Netzwerk hinzugefügt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cbb075-7455-4170-acfb-71f5332ed65c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        self.layers = []\n",
    "        self.activation_functions = []\n",
    "\n",
    "    def add_layer(self, layer, activation_function):\n",
    "        \"\"\"\n",
    "        Fügt eine instanzierte Schicht \"layer\" mit ihrer entsprechenden Aktivierungsfunktion\n",
    "        \"activation_function\" zum Netzwerk hinzu.\n",
    "        \"\"\"\n",
    "        self.layers.append(layer)\n",
    "        self.activation_functions.append(activation_function)\n",
    "\n",
    "    def forward_propagation(self, inputs):\n",
    "        \"\"\"\n",
    "        Berechnet die Vorhersagen \"predictions\" des Netzwerkes anhand der Eingabewerte\n",
    "        \"inputs\" der Eingabeschicht.\n",
    "        \"\"\"\n",
    "        current_inputs = inputs\n",
    "        for layer, activation_function in zip(self.layers, self.activation_functions):\n",
    "            raw_outputs = layer.forward(current_inputs)\n",
    "            activated_outputs = activation_function.forward(raw_outputs)\n",
    "            # Aktivierte Ausgaben der Schicht werden als Eingabewerte für die nächste Schicht verwendet\n",
    "            current_inputs = activated_outputs\n",
    "        predictions = current_inputs\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2010db8e-5b36-4232-b7e3-0ace0c3d5a27",
   "metadata": {},
   "source": [
    "Als Beispiel erstelle ich ein Netzwerk, das aus 2 Eingabeneuron, 4 versteckte Neuronen und 5 Ausgabeneuronen besteht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb1f69-0cef-4074-9bdc-b7402fb52813",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "network.add_layer(\n",
    "    Layer(2, 4),  # Eingabeschicht → versteckte Schicht\n",
    "    ReLU(),  # Aktivierungsfunktion für die versteckte Schicht\n",
    ")\n",
    "network.add_layer(\n",
    "    Layer(4, 5),  # Versteckte Schicht → Ausgabeschicht\n",
    "    Softmax(),  # Aktivierungsfunktion für die Ausgabeschicht\n",
    ")\n",
    "\n",
    "network.forward_propagation(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f40d1-23cc-4563-b4bf-a3fae3b2943e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Das Zahlungserkennungsmodell\n",
    "\n",
    "Um ein neuronales Netzwerk zu trainieren, werden Daten benötigt. Für ein Modell, das zu der Erkennung von Zahlen dient, eignet sich die MNIST-Datenbank. MNIST enthält 60.000 Trainingsbilder und 10.000 Testbilder von handgeschriebenen Ziffern und kann somit zum Trainieren als auch für die Evaluierung verwendet werden. (vgl. Khan, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f557db4-64de-4ee5-a388-758c4c420790",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Für mein neuronales Netzwerk verwende ich für die Eingabeschicht 784 Neuronen, da die MNIST Bilder aus 28 mal 28 Pixels bestehen. Ich habe eine verborgene Schicht mit \n",
    "20 Neuronen mit der ReLU-Aktivierungsfunktion. Die Ausgabeschicht besteht aus zehn Neuronen, die jeweils die Ziffern null bis neun repräsentieren. Da es sich hier um ein Klassifizierungsproblem handelt, verwende ich für die Ausgabeschicht die Softmax-Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5d2bb2-8ae2-428b-8589-48d1abec6aa7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "from daten.lade_daten import lade_test_daten\n",
    "import random\n",
    "\n",
    "network = Network()\n",
    "network.add_layer(\n",
    "    Layer(784, 20),  # Eingabeschicht → versteckte Schicht\n",
    "    ReLU(),  # Aktivierungsfunktion für die versteckte Schicht\n",
    ")\n",
    "network.add_layer(\n",
    "    Layer(20, 10),  # Versteckte Schicht → Ausgabeschicht\n",
    "    Softmax(),  # Aktivierungsfunktion für die Ausgabeschicht\n",
    ")\n",
    "\n",
    "def test_neural_network(network):\n",
    "    # Bilder (Eingabewerte) und labels (tatsächliche Zielwerte als Wahrscheinlichkeiten)\n",
    "    images, labels = lade_test_daten()\n",
    "    \n",
    "    # Vorhersagen als Wahrscheinlichkeitsverteilung\n",
    "    predictions = network.forward_propagation(images)\n",
    "    \n",
    "    # Vorhersagen als Ziffern\n",
    "    predicted_numbers = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # tatsächliche Zielwerte als Ziffern\n",
    "    actual_values = np.argmax(labels, axis=1)\n",
    "    \n",
    "    # Vektor aus \"Richtig Falsch\" Werten\n",
    "    comparisons = predicted_numbers == actual_values\n",
    "    \n",
    "    # Summe / Anzahl an richtigen Aussagen\n",
    "    n_correct_predictions = sum(comparisons)\n",
    "    \n",
    "    # Genauigkeit des neuronalen Netzwerkes\n",
    "    accuracy = n_correct_predictions / 10_000\n",
    "    print(accuracy)\n",
    "\n",
    "test_neural_network(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3111f6d4-da22-4725-ac8a-bfebe385a3ac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Zuerst werden die Bilder \"images\" und deren Beschriftungen \"labels\" geladen. Anschließend berechnet das neuronale Netzwerk Vorhersagen \"predictions\" basierend auf den Bilddaten und gibt diese als Wahrscheinlichkeitsverteilung zurück. Die Ziffer mit der höchsten Wahrscheinlichkeit wird dann mit der tatsächlichen Ziffer je Trainingsbesipiel verglichen. Um die Genauigkeit zu bestimmen, werden die richtigen Aussagen mit der gesamten Anzahl an Testbildern dividiert. Da das Netzwerk noch nicht trainiert wurde, ist die Genauigkeit sehr niedrig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c04bc-0d8d-4b09-9e34-e9ac53768d62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Trainieren eines neuronalen Netzwerkes\n",
    "\n",
    "## Deep- und Shallow Learning\n",
    "\n",
    "Deep Learning und Shallow Learning sind Teilbereiche des Machine Learning und befassen sich mit dem Trainieren neuronaler Netzwerke. Shallow Learning wird verwendet, um flache (shallow) neuronale Netzwerke zu trainieren, die in der Regel aus zwei oder drei Schichten bestehen. Deep Learning hingegen wird bei tiefen (deep) neuronalen Netzwerken angewendet, um Netzwerke mit mehr als zwei versteckten Schichten zu trainieren. (vgl. Lodhi, o.J.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e3bc71-0aba-424f-965c-e5e350f5f149",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Flache neuronale Netzwerke sind aufgrund ihrer vereinfachten Architektur schneller und einfacher zu trainieren. Allerdings eignen sie sich daher weniger gut für komplexe Probleme. Tiefe Netzwerke hingegen können durch ihre komplexe Struktur anspruchsvolle Probleme lösen, erfordern jedoch zusätzliche Methoden um Problemen wie Überanpassung zu vermeiden. (ebd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb48ae0-4c99-4052-993c-b993e0be3b59",
   "metadata": {},
   "source": [
    "Bei dem im vorherigen Kapitel angesprochenen Zahlungserkennungsmodell handelt es sich um ein flaches neuronales Netzwerk, da es nur eine versteckte Schicht besitzt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27576445-89eb-4f9e-b7ed-cc79756e1b58",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Die Loss Function und die Cost Function\n",
    "\n",
    "Die Begriffe Loss Function (Verlustfunktion) und Cost Function (Kostenfunktion) werden häufig synonym verwendet, haben jedoch grundlegend unterschiedliche Bedeutungen. Die Loss Function bewertet die Leistung einer einzelnen Vorhersage. Sie berechnet den Fehler des Netzwerks für ein einzelnes Trainingsbeispiel, indem sie die Vorhersage mit dem tatsächlichen Zielwert vergleicht. (vgl. Alake, o.J.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29110bbd-f090-4eb2-a136-8916a9e0e136",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Im Gegensatz dazu ist die Cost Function der Mittelwert der Loss Function über das gesamte Trainingsset. Sie bewertet die Gesamtleistung des neuronalen Netzwerks und spielt eine zentrale Rolle im Trainingsprozess. Das Ziel des Netzwerks ist es, die Kosten zu minimieren, um die Genauigkeit der Vorhersagen zu maximieren. (ebd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70cc189-73d8-4b3b-963d-db7b0a72f32c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Es gibt verschiedene Arten von Cost Function, die je nach Aufgabestellung in zwei Kategorien eingeteilt werden können: Cost Functions für Regressionsprobleme und Cost Functions für Klassifikationsprobleme. (ebd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c463410-b4da-40a2-b47d-e91924b758f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Cost Functions für Regressionsprobleme\n",
    "\n",
    "Typische Cost Functions für Regressionsprobleme sind der Mean Absolute Error (MAE) und der Mean Squared Error (MSE). Der Mean Absolute Error berechnet den Mittelwert der absoluten Differenzen zwischen den Vorhersagen und den tatsächlichen Zielwerten. (vgl. Alake, o.J.) Mathematisch wird sie so dargestellt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fecf6a0-2edf-4703-91df-0240d2567f7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$MAE = {\\frac {1} {N}} \\sum_{i=1}^{N} \\sum_{j=1}^{n} |\\hat{y}_{ij} - y_{ij}|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fdfbed-e06c-4166-bbd3-712d95659415",
   "metadata": {},
   "source": [
    "Hierbei steht $N$ für die Anzahl an Trainingsbeispielen, $n$ für die Anzahl an Ausgabewerten, $\\hat{y}_j$ für einen vorhergesagten Wert des $j$-te Ausgabewerts für das $i$-te Trainingsbeispiels $j$ und $y_ij$ für den tatsächliche Zielwert für diesen Ausgabewert und diesen Trainingsbeispiels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c01f5-4fb5-43ad-a07f-47484edec06c",
   "metadata": {},
   "source": [
    "Der Mean Squared Error hingegen berechnet die quadratischen Differenzen zwischen den Vorhersagen und den tatsächlichen Zielwerten. Durch das Quadrieren werden größere Differenzen stärker bestraft, was den MSE empfindlicher gegenüber Ausreißern macht. (ebd.):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c792099f-5585-4c5e-b3ca-062e9f84e8de",
   "metadata": {},
   "source": [
    "$$MSE = {\\frac {1} {N}} \\sum_{i=1}^{N} \\sum_{j=1}^{n} (\\hat{y}_{ij} - y_{ij})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2656f-c843-426c-b4c7-4cf110eb69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError:\n",
    "    def calculte_cost(predictions, targets):\n",
    "        losses = np.sum(np.square(predictions - targets), axis=1)\n",
    "        cost = np.mean(losses)\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68007192-c931-4835-8ea1-68d5ea1d9ae5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Für mein Programm werde ich nur den Mean Squared Error verwenden. Zuerst werden die Verluste \"losses\" berechnet, indem ich die Vorhersagen \"predictions\" von den Zielen \"targets\" subtrahiere und dann die Ergebnisse mit \"np.square\" quadriere. Da es mehrere Ausgabewerte pro Beispiel gibt, wird für jedes Beispiel der Verlust über alle Ausgabewerte summiert. Danach berechne ich die Kosten \"cost\" indem ich den Mittelwert aller Verluste  bilde und diesen ausgebe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6eadb6-39a3-4bce-8983-56a13d0c6088",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Cost Functions für Klassifizierungsprobleme\n",
    "\n",
    "Eine typische Cost Function für Klassifizierungsprobleme ist der Categorical Cross Entropy (CCE). Um den Verlust $L$ eines einzelnen Trainingsbeispiel $i$ zu erhalten, wird die negative Summe aller tatsächlichen Zielwerte $y_{ij}$ multipliziert mit den jeweiligen logerierten Vorhersagen $\\hat{y}_{ij}$ berechnet (vgl. Gómez Bruballa, 2018):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066182ea-510e-4dfb-88bb-ac95039d34e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$L_i = -{\\sum_{j=1}^{C} y_{ij} \\log(\\hat{y}_{ij}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2735ee6-df49-4b3a-a66f-47a9b9be1903",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Hierbei steht $C$ für die Anzahl an Klassen. Um die Kosten für alle Trainingsbeispiele zu berechnen wird der mittelwert aller Verluste wie bei den anderen Cost-Funktionen berechnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8fe25-dddf-495a-b477-93eac9d39433",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$CCE = {\\frac {1} {N}} {\\sum_{i=1}^{N} {L_{i}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55172a0c-ef1e-424b-8239-ace0c3f8e957",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "class CategoricalCrossEntropy:\n",
    "    def calculte_cost(predictions, targets):\n",
    "        vorhersagen = np.clip(predictions, 1e-7, 1 - 1e-7)\n",
    "        losses = -np.sum(targets * np.log(predictions), axis=1)\n",
    "        cost = np.mean(losses)\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35845a62-0340-4f24-be26-d962f4d391f2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Für mein Zahlungserkennungsmodell werde ich des Weiteren den Categorical Cross Entropy verwenden. Zuerst begrenze ich die Vorhersagen, damit die Werte nicht zu nah an null oder eins sind, um beim Logarithmieren Verzerrungen der Ergebnisse zu vermeiden. Danach berechne ich die Verluste \"losses\" in dem ich mit \"np.log\" die Vorhersagen \"predictions\" logarithmiere und dann mit den Zielen \"targets\" multipliziere. Die Ergebnisse werden über alle Klassen mit \"np.sum\" summiert. Um die Kosten \"cost\" zu berechnen verwende ich wieder \"np.mean\" um den Mittellwert aller Losses zu berechnen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650f706-9c56-411f-b74f-005ec8d842a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Die Objective Function\n",
    "\n",
    "Die Objective Function (Zielfunktion) ist eine Funktion, die im Optimierungsprozess entweder minimiert oder maximiert wird. Die Rolle der Objective Function variiert je nach Bereich  des Machine Learning. Im Reinforcement Learning zielt die Objective Function darauf ab, die kumulative Belohnung eines Agenten über eine Reihe von Aktionen zu maximieren. (vgl. Muns, o.J.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b8e341-a47e-46b6-a49f-9a25bc552035",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Im Deep Learning ist das Ziel der Objective Function, die Cost Function zu minimieren, indem die trainierbaren Parameter des neuralen Netzwerkes - also die Gewichte und Bias-Werte - angepasst werden. (vgl. Dey, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa436336-2bce-4f1f-933a-1a8b8b2f05af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Dieses Kapitel konzentriert sich auf die Objective Function im Kontext des Deep Learning, wobei die Objective Function in diesem Fall auch als die Cost Function bezeichnet werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e519b8c-e0eb-43df-ab3a-e79ba0347611",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die Formel einer Cost Function kann wie folgt dargestellt werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b53b8-584f-41f2-aa69-33a33172e52a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$J(\\theta) = {\\frac 1 N} \\sum_{i=1}^N {L(y_i, f(x_i, \\theta))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0ffe7-a69b-4a3b-bbdb-81df4affb3f2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Dabei steht $\\theta$ für die trainierbaren Parameter des neuronalen Netzwerkes, $x_i$ für die Eingabewerte des $i$-ten Trainingsbeispiels und $L$ für die Loss Function, die den Verlust zwischen dem tatsächlichen Zielwert $y_i$ und der Vorhersage $f(x_i, \\theta)$ eines neuronalen Netzwerks mit den Parametern $\\theta$ angibt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66e3659-1572-456d-8701-d8652138d7c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Gradient Descent ist ein Optimisation Algorithm. Er wird verwendet, um lokale Minimumstellen einer Funktion iterativ zu approximieren. Im Bereich des Machine Learning wird der Gradient Descent verwendet, um die Parameter eines neuronalen Netzwerks iterativ so anzupassen, dass die Cost Function minimiert wird. Der Algorithmus lässt sich wie ein Ball auf einer Landschaft mit Hügeln und Tälern darstellen, der schrittweise das Tal (das Minima) hinunterrollt, um den optimalen Punkt zu finden (vgl. Singh, 2025)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc6e9f-b964-45da-bc4a-7b7f5d007404",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_input",
     "image"
    ]
   },
   "outputs": [],
   "source": [
    "# Zeichne Cost-Landschaft mit Code\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from neuronales_netzwerk.verlustfunktionen import MittlererQuadratischerFehler\n",
    "\n",
    "def f(x):\n",
    "    return 2 * x + 2\n",
    "\n",
    "\n",
    "eingaben = np.arange(-3, 3, 0.1)\n",
    "ziele = f(eingaben)\n",
    "\n",
    "\n",
    "def berechne_kostenfunktion_auf_gewicht_bias(gewichte, bias):\n",
    "    vorhersagen = gewichte * eingaben + bias\n",
    "    verlust = MittlererQuadratischerFehler.kosten(vorhersagen, ziele)\n",
    "    return verlust\n",
    "\n",
    "\n",
    "def berechne_gradient(gewicht, bias):\n",
    "    vorhersagen = gewicht * eingaben + bias\n",
    "    verlust_gradient = MittlererQuadratischerFehler.rueckwaerts(vorhersagen, ziele)\n",
    "\n",
    "    gradient_gewicht = np.dot(eingaben.T, verlust_gradient)\n",
    "    gradient_bias = np.sum(verlust_gradient)\n",
    "    return [gradient_gewicht, gradient_bias]\n",
    "\n",
    "\n",
    "def zeichne_landschaft():\n",
    "    gewichtsbereich = np.arange(-1, 4, 0.1)\n",
    "    biasbereich = np.arange(-1, 4, 0.1)\n",
    "    gewichte, bias = np.meshgrid(gewichtsbereich, biasbereich)\n",
    "    verluste = np.array(\n",
    "        [\n",
    "            [\n",
    "                berechne_kostenfunktion_auf_gewicht_bias(gewicht, bias_wert)\n",
    "                for gewicht in gewichtsbereich\n",
    "            ]\n",
    "            for bias_wert in biasbereich\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ax.plot_surface(\n",
    "        gewichte,\n",
    "        bias,\n",
    "        verluste,\n",
    "        cmap=\"coolwarm\",\n",
    "    )  # Kostenlandschaft\n",
    "\n",
    "def berechne_hinunterrollen():\n",
    "    geschichte = []\n",
    "    gewicht = -1  # Start Gewicht\n",
    "    bias = -1  # Start Bias\n",
    "    for _ in range(30):\n",
    "        vorhersagen = gewicht * eingaben + bias\n",
    "        kosten = MittlererQuadratischerFehler.kosten(vorhersagen, ziele)\n",
    "\n",
    "        geschichte.append((gewicht, bias, kosten))\n",
    "\n",
    "        gradient = berechne_gradient(gewicht, bias)\n",
    "        gewicht -= 0.02 * gradient[0]\n",
    "        bias -= 0.02 * gradient[1]\n",
    "\n",
    "    return geschichte\n",
    "\n",
    "\n",
    "def zeichne_hinunterrollen(punkte):\n",
    "    gewichte = [p[0] for p in punkte]\n",
    "    bias = [p[1] for p in punkte]\n",
    "    kosten = [p[2] for p in punkte]\n",
    "    ax.plot(\n",
    "        gewichte,\n",
    "        bias,\n",
    "        kosten,\n",
    "        color=\"red\",\n",
    "        marker=\"o\",\n",
    "        markersize=5,\n",
    "        label=\"Descent Path\",\n",
    "    )\n",
    "    for i in range(len(punkte) - 1):\n",
    "        gewicht, bias, kosten = punkte[i]\n",
    "        dgewicht = punkte[i + 1][0] - gewicht\n",
    "        dbias = punkte[i + 1][1] - bias\n",
    "        dkosten = punkte[i + 1][2] - kosten\n",
    "        ax.quiver(\n",
    "            gewicht,\n",
    "            bias,\n",
    "            kosten,\n",
    "            dgewicht,\n",
    "            dbias,\n",
    "            dkosten,\n",
    "            arrow_length_ratio=0.5,\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\", computed_zorder=False)\n",
    "#ax = fig.add_axes((-0.15, 0.05, 1, 1),projection=\"3d\", computed_zorder=False)\n",
    "\n",
    "zeichne_landschaft()\n",
    "geschichte = berechne_hinunterrollen()\n",
    "zeichne_hinunterrollen(geschichte)\n",
    "\n",
    "# Achsentitel\n",
    "ax.set_xlabel(\"Gewicht (w)\")\n",
    "ax.set_ylabel(\"Bias (b)\")\n",
    "ax.invert_yaxis()\n",
    "ax.set_zlabel(\"Kosten (L)\", labelpad=-260)\n",
    "\n",
    "bild = BytesIO()\n",
    "plt.savefig(bild, format=\"png\", bbox_inches='tight', pad_inches=0)\n",
    "bild.seek(0)\n",
    "plt.close()\n",
    "\n",
    "html = erstelle_bild(bild, 400, \"Cost-Landschaft in Bezug auf Gewichte und Bias\")\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07533968-30ee-434c-a2a5-8f5f6ea2bcb1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Der Algorithmus berechnet zunächst den Gradienten. Der Gradient gibt an, in welcher Richtung und mit welcher Stärke die Funktion am stärksten ansteigt. Um also die Cost Function zu minimieren, werden die Parameter in Richtung des negativen Gradienten angepasst. Dazu werden die partiellen Ableitungen der Cost Function nach den Gewichten und Bias-Werten berechnet. (ebd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d0786-8638-4c8e-a5c1-9a67b5f94cf8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die Cost-Funktion misst den Fehler zwischen den Vorhersagen des Modells und den tatsächlichen Zielwerten. Da die Gewichte und Bias-Werte die Vorhersagen beeinflussen, haben sie demnach einen Einfluss auf die Cost Function. Allerdings tragen einige Parameter stärker zur Veränderung der Cost Function bei als andere. Deshalb werden die Parameter proportional zu ihrer Änderungsrate angepasst. Die Partielle Ableitung zeigt an, wie empfindlich die Cost-Funktion auf Änderungen eines bestimmten Parameters reagiert. Gewichte, die eine große Änderung der Cost Function bewirken, werden entsprechend stärker angepasst, um den Fehler zu verringern, während Gewichte mit geringerem Einfluss nur minimal verändert werden. (ebd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b5de9-33e2-455a-9ea7-b3e6dcc6b444",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Ein weiterer wichtiger Bestandsteil von Gradient Descent ist die Lernrate (Learning Rate). Die Lernrate ist ein Hyperparameter, der die Schrittgröße in jeder Iteration des Gradient Descent Algorithmus bestimmt. Es ist entscheidend, eine geeignete Lernrate auszuwählen, um den Trainingsprozess effizient zu gestalten. Ist die Lernrate zu niedrig, verläuft der Lernprozess sehr langsam und benötigt viele Iterationen Eine zu hohe Lernrate hingegen kann dazu führen, dass der Algorithmus das Minimum überschreitet und nicht zu einer optimalen Lösung führt (vgl. Pabasara, 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754be2bb-8711-49f9-b97a-cb7703537d1b",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_input",
     "image"
    ]
   },
   "outputs": [],
   "source": [
    "# Zeichne Gradient Descent mit verschiedenen Lernrate mit Code\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from neuronales_netzwerk.verlustfunktionen import MittlererQuadratischerFehler\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return 2 * x\n",
    "\n",
    "\n",
    "inputs = np.arange(0, 4, 0.1)\n",
    "targets = f(inputs)\n",
    "\n",
    "\n",
    "def calculate_cost_weight_graph(weights):\n",
    "    cost_weight_graph = []\n",
    "    for weight in weights:\n",
    "        predictions = weight * inputs\n",
    "        cost = MittlererQuadratischerFehler.kosten(predictions, targets)\n",
    "        cost_weight_graph.append(cost)\n",
    "    return cost_weight_graph\n",
    "\n",
    "\n",
    "def calculate_gradient(weight):\n",
    "    predictions = weight * inputs\n",
    "    gradient_cost = MittlererQuadratischerFehler.rueckwaerts(predictions, targets)\n",
    "    gradient_weight = np.dot(inputs.T, gradient_cost)\n",
    "    return gradient_weight\n",
    "\n",
    "\n",
    "def draw_gradient_descent(learning_rate):\n",
    "    weights_history = []\n",
    "    cost_history = []\n",
    "    weight = 0  # Start Gewicht\n",
    "    cost = 5\n",
    "    while cost > 0.01:\n",
    "        weights_history.append(weight)\n",
    "        predictions = weight * inputs\n",
    "        cost = MittlererQuadratischerFehler.kosten(predictions, targets)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        gradient_weight = calculate_gradient(weight)\n",
    "        weight -= learning_rate * gradient_weight\n",
    "\n",
    "    plt.scatter(weights_history, cost_history, color=\"red\", zorder=2)\n",
    "    plt.plot(weights_history, cost_history, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "gewichte = np.arange(0, 4, 0.1)\n",
    "cost_weight_graph = calculate_cost_weight_graph(gewichte)\n",
    "\n",
    "def display_gradient_descent(learning_rate, label):\n",
    "    plt.xlabel(\"Gewichte (w)\")\n",
    "    plt.ylabel(\"Kosten (L)\")\n",
    "    plt.plot(inputs, cost_weight_graph)\n",
    "    draw_gradient_descent(learning_rate)\n",
    "\n",
    "    bild = BytesIO()\n",
    "    plt.savefig(bild, format=\"png\", bbox_inches='tight')\n",
    "    bild.seek(0)\n",
    "    plt.close()\n",
    "    picture = erstelle_bild(bild, 500, label)\n",
    "    return picture\n",
    "\n",
    "picture1 = display_gradient_descent(0.001, \"Gradientenabstieg mit zu niedriger Lernrate\")\n",
    "picture2 = display_gradient_descent(0.18, \"Gradientenabstieg mit zu hoher Lernrate\")\n",
    "picture3 = display_gradient_descent(0.02, \"Gradientenabstieg mit optimaler Lernrate\")\n",
    "\n",
    "html = f\"\"\"\n",
    "    <div style=\"display:grid; grid-template-columns: repeat(3, 1fr);\">\n",
    "        {picture1}\n",
    "        {picture2}\n",
    "        {picture3}\n",
    "    </div>\n",
    "\"\"\"\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de10149-ab70-4a55-bea3-babb4ca1a871",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Nachdem der Gradient berechnet wurde, erfolgt die iterative Anpassung der trainierbaren Parameter des neuronalen Netzwerks. Dies geschieht, indem die Parameter um den Gradienten, multipliziert mit der Lernrate, verringert werden (vgl. Singh, 2025). Die Formel lässt sich wie folgt darstellen:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de78a97-3541-4a92-b0e4-26de26e72cd9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$\\theta := \\theta - \\eta \\nabla J(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b90245a-bbb9-4c5c-a59f-40295a7a4574",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Dabei steht $\\theta$ für die Parameter des neuronalen Netzwerks, $\\eta$ für die Lernrate und $\\nabla J(\\theta)$ für den Gradienten der Cost-Funktion in Bezug auf die Parameter $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa680516-b9c2-420d-ba5b-d2787e624230",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Um Gradient Descent zu implementieren, erstelle ich die Klasse \"GD\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b7a87-f2ea-4a2c-957b-8d8bc414fe3f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GD:\n",
    "    def __init__(self, network, learning_rate):\n",
    "        \"\"\"\n",
    "        network: Das Netzwerk, das optimiert werden soll\n",
    "        learning_rate: Die Lernrate, die die Schrittgröße bestimmt\n",
    "        \"\"\"\n",
    "        self.network = network\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def update_parameters(self):\n",
    "        \"\"\"\n",
    "        Aktualisiert die Parameter (Gewichte und Bias-Werte) aller Schichten im Netzwerk basierend auf den Gradienten\n",
    "        \"\"\"\n",
    "        # Iteriert über alle Schichten des Netzwerks und aktualisiert deren Parameter\n",
    "        for layer in self.network.layers:\n",
    "            # Aktualisiert die Gewichte der aktuellen Schicht mit dem negativen Gradienten\n",
    "            # multipliziert mit der Lernrate, um den Schritt zu skalieren\n",
    "            layer.weights -= self.learning_rate * layer.gradient_weights\n",
    "            # Aktualisiert die Bias-Werte der aktuellen Schicht mit dem negativen Gradienten\n",
    "            # multipliziert mit der Lernrate, um den Schritt zu skalieren\n",
    "            layer.bias -= self.learning_rate * layer.gradient_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a792d-2923-48b5-a8b4-f3622dc408b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Im Konstruktor der Klasse speichere ich das neuronale Netzwerk „network“ und die Lernrate „learning_rate“. Momentan enthält die Klasse nur die Methode „update_parameters“. Diese Methode verwende ich, um die trainierbaren Parameter – also die Gewichte „layer.weights“ und die Bias-Werte „layer.bias“ – jeder Schicht im Netzwerk basierend auf den negativen Gradienten und der Lernrate zu aktualisieren. Der genaue Trainingsprozess und die Berechnung der Gradienten werden in den folgenden Kapiteln erklärt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ec74b-7709-4599-9cec-90bab9e875e0",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GD:\n",
    "    def __init__(self, network):\n",
    "        self.network = network\n",
    "\n",
    "    def update_parameters(self, learning_rate):\n",
    "        # Aktualisiere Gewichte und Bias basierend auf den Gradienten\n",
    "        for layer in network.layers:\n",
    "            # Aktualisiert die Gewichte\n",
    "            layer.weights -= self.learning_rate * schicht.gradient_weights\n",
    "            # Aktualisiert die Bias-Werte\n",
    "            layer.bias -= self.learning_rate * schicht.gradient_bias\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        inputs,\n",
    "        targets,\n",
    "        epochs,\n",
    "        learning_rate,\n",
    "    ):\n",
    "        for _ in range(epochs):\n",
    "            # Vorwärtsdurchlauf: Berechnung der Vorhersagen\n",
    "            predictions = network.forward_propagation(inputs)\n",
    "\n",
    "            # Rückwärtsdurchlauf: Berechnung der Gradienten\n",
    "            network.backpropagation(predictions, targets)\n",
    "\n",
    "             # Aktualisiere Gewichte und Bias basierend auf den Gradienten\n",
    "            self.update_parameters(learning_rate)\n",
    "\n",
    "gd = GD(network)\n",
    "gd.train(images, labels, 1000, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29fa4f-2b9d-4053-bf31-aba5e66459e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Momentan besitz diese Klasse nur die Methode \"update_parameters\".\n",
    "\n",
    "Um Gradient Descent zu implementieren, erstelle ich die Klasse \"GD\". In der Methode \"train\" wird zuerst mit der Methode \"network.forward_propagation\" die Vorhersagen generiert. Danach wird mit \"netzwerk.backpropagation\" der Gradient berechnet. Danach werden die Gewichte und Bias-Werte mit der Methode \"update_parameters\" aktualisiert. Diese Methode addiert Gewichte und Bias-Werte mit den jeweiligen negativen Steigungen multipliziert mit der Lernrate. Dieser Vorgang wird mehrere Male wiederholt um das neuronale Netzwerk iterativ zu verbessern. Allerdings erklärt dieser Code Abschnitt nicht, wie der Gradient berechnet wird. Das wird im nächsten Kapitel erklärt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46e6518-8337-42e6-9b14-b08084e00228",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Backpropagation\n",
    "\n",
    "Backpropagation ist ein wichtiger Bestandteil im maschinellen Lernen und wird zusammen mit Optimisation Algorithms wie Gradient Descent verwendet, um die Gewichte und Bias-Werte eines neuronalen Netzwerkes anzupassen und somit die Cost Function zu minimieren. Backpropagation nutzt Ableitungsregeln wie die Kettenregel, um den Gradienten der Cost Function effizient in Bezug auf alle Gewichte und Bias-Werte zu berechnen. (vgl. Kostadinov, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35508522-be8c-46e9-b42f-1ad3d029f69f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Der Algorithmus kann in drei Schritte unterteilt werden: Der erste Teil wird als \"Forward Pass\" oder \"Forward Propagation\" bezeichnet und berechnet eine Vorhersage basierend auf gegebene Eingabedaten. Im zweiten Schritt werden mit Cost Functions die Vorhersagen mit den tatsächlichen Zielwerten verglichen und evaluiert. Der letzte Schritt ist der \"Backwards Pass\" und hier werden die berechneten Fehler bei der Evaluierung im Netzwerk schichtweise zurück propagiert. Dabei wird berechnet, wie sehr eine Schicht und ein Gewicht oder Bias-Wert zum Fehler beitragen. (ebd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6dd2f7-ecdd-439f-8d55-b181619604a9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Angenommen, man betrachten ein stark vereinfachtes neuronales Netzwerk mit jeweils nur einem Neuron pro Schicht. In diesem Fall besitzt jedes Neuron lediglich ein Gewicht und einen Bias-Wert. Die Verbindungen zwischen den Gewichten und Bias-Werten zur Cost Function lassen sich wie folgt darstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3dce0-9478-4a7f-96da-175f15cb6f84",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_input",
     "image"
    ]
   },
   "outputs": [],
   "source": [
    "# Zeichne ein neuronales Netzwerk Graphen Diagramm mit Code\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes with positions\n",
    "positions = {\n",
    "    \"$w^L$\": (0, 3),\n",
    "    \"$a^{L-1}$\": (1, 3),\n",
    "    \"$b^L$\": (2, 3),\n",
    "    \"$z^L$\": (1, 2),\n",
    "    \"$a^L$\": (1, 1),\n",
    "    \"$J$\": (1, 0),\n",
    "}\n",
    "\n",
    "# Add edges (arrows) between nodes\n",
    "edges = [\n",
    "    (\"$w^L$\", \"$z^L$\"),\n",
    "    (\"$b^L$\", \"$z^L$\"),\n",
    "    (\"$a^{L-1}$\", \"$z^L$\"),\n",
    "    (\"$z^L$\", \"$a^L$\"),\n",
    "    (\"$a^L$\", \"$J$\"),\n",
    "]\n",
    "\n",
    "# Add nodes and edges to the graph\n",
    "G.add_nodes_from(positions.keys())\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Plot the graph using networkx\n",
    "plt.figure(figsize=(8, 6))\n",
    "nx.draw(G, pos=positions, with_labels=True, node_size=5000, node_color=\"lightblue\", font_size=20, font_weight=\"bold\", arrows=True, edgecolors=\"black\")\n",
    "\n",
    "# Display the plot\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "bild = BytesIO()\n",
    "plt.savefig(bild, format=\"png\")\n",
    "bild.seek(0)\n",
    "plt.close()\n",
    "\n",
    "html = erstelle_bild(bild, 300, \"Neuronales Netzwerk Diagram\")\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e74768-1826-42c7-a56a-0d48d02b549e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Hierbei steht $w$ für das Gewicht, $b$ für den Bias-Wert, $z$ für die rohe Ausgabe und $a$ für die aktivierte Ausgabe. $J$ repräsentiert die Cost Function für ein einzelnes Trainingsbeispiel, während $L$ die Ausgabechicht des neuronalen Netzwerks bezeichnet und $L-1$ die vorletzte Schicht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eb6efd-0a03-4126-8b81-aff218a75377",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In der gegebenen Darstellung beeinflusst das Gewicht $w^L$ die rohe Ausgabe $z^L$, die durch die Aktivierungsfunktion transformiert wird, um die aktivierte Ausgabe $a^L$ zu erzeugen. Diese aktivierte Ausgabe $a^L$ stellt die Vorhersage des neuronalen Netzwerks dar und hat somit Einfluss auf die Cost Function $J$. Um den Gradienten der Cost Function in Bezug auf die Gewichte und Bias-Werte zu berechnen, werde ich die Formeln rückwärts unter der Verwendung der Kettenregel propagieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bd5c55-5d3a-4a3a-b31b-653a6d560d4f",
   "metadata": {},
   "source": [
    "Zur Berechnung der partiellen Ableitung der Cost Function in Bezug auf die rohe Ausgabe $z^L$, kann die folgende Formel verwendet werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69c584-c7a1-4015-bd11-e60234ca1ddb",
   "metadata": {},
   "source": [
    "$${\\frac {\\partial J} {\\partial z^L}} = {\\frac {\\partial a^L} {\\partial z^L}} {\\frac {\\partial J} {\\partial a^L}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d443f1-b526-4256-be37-6340657171c4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Ein neuronales Netzwerk besitzt allerdings in der Regel mehrere Neuronen pro Schicht. Daher sieht die partielle Ableitung der Cost Function in Bezug auf die rohe Ausgabe $z_j^J$ eines bestimmten Neurons in der Ausgabechicht $L$ stattdessen so aus:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a173279-b8b3-4120-a184-72ad2d8db60b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$${\\frac {\\partial J} {\\partial z_j^L}} = {\\frac {\\partial a_j^L} {\\partial z_j^L}} {\\frac {\\partial J} {\\partial a_j^L}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425d11d-f2b6-4e4f-b058-1daa2b9c487c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Hierbei bezeichnet $j$ ein beliebiges Neuron innerhalb der Ausgabeschicht $L$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39185967-6cdc-4817-9c99-619cd327c91c",
   "metadata": {},
   "source": [
    "Ein Gewicht $w_{jk}^L$, ein Bias-Wert $b_j^L$ und eine aktivierte Ausgabe $a_k^{L-1}$ in der Ausgabeschicht wirken sich auf diese rohe Ausgabe $z_j^L$ aus. Die partiellen Ableitungen der Cost Function in Bezug auf dieses Gewicht, diesen Bias-Wert und diese aktivierte Ausgabe ergeben sich wie folgt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936a1fa-7d7c-41ea-b231-2687e66219d9",
   "metadata": {},
   "source": [
    "$${\\frac {\\partial J} {\\partial w_{jk}^L}} = {\\frac {\\partial z_j^L} {\\partial w_{jk}^L}} {\\frac {\\partial J} {\\partial z_j^L}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9181a14-86f0-440d-9961-a735d6c553e4",
   "metadata": {},
   "source": [
    "$${\\frac {\\partial J} {\\partial b_{j}^L}} = {\\frac {\\partial z_j^L} {\\partial b_{j}^L}} {\\frac {\\partial J} {\\partial z_j^L}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e88ba3-46f9-47ab-9439-5b0b5405bb39",
   "metadata": {},
   "source": [
    "$${\\frac {\\partial J} {\\partial a_k^{L-1}}} = \\sum_{j=1}^m {\\frac {\\partial z_j^L} {\\partial a_k^{L-1}}} {\\frac {\\partial J} {\\partial z_j^L}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b212b65-ccf3-4664-add6-f744704c3ddc",
   "metadata": {},
   "source": [
    "Dabei bezeichnet $k$ das Neuron in der vorherigen Schicht $L-1$. Das Gewicht $w_{jk}^L$ stellt demnach die Verbindung zwischen dem $k$-ten Neuron der vorletzten Schicht und dem $j$-ten Neuron der Ausgabeschicht dar. Die aktivierte Ausgabe $a_k^{L-1}$ hat Einfluss auf alle Neuronen in der Ausgabeschicht und somit auf alle rohen Ausgaben $z_j^L$. Aus diesem Grund werden die partiellen Ableitungen summiert. Dabei bezeichnet $m$ die Anzahl der Neuronen in der Ausgabeschicht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97012ed9-4e86-4638-98c4-ddd146b39efb",
   "metadata": {},
   "source": [
    "Die partielle Ableitung auf eine rohe Ausgabe $z_k^{L-1}$ sieht ähnlich aus wie die nach $z^L$:\n",
    "\n",
    "Die partielle Ableitung der Cost Function in Bezug auf eine rohe Ausgabe $z_k^{L-1}$ in der Schicht $L-1$ sieht ähnlich aus wie die Ableitung in Bezug auf die rohe Ausgabe $z^L$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9461df-8530-4296-a896-00c5feb0f6d5",
   "metadata": {},
   "source": [
    "$${\\frac {\\partial J} {\\partial z_k^{L-1}}} = {\\frac {\\partial a_k^{L-1}} {\\partial z_k^{L-1}}} {\\frac {\\partial J} {\\partial a_k^{L-1}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb9521d-2f48-443b-bcd5-549ba5d81dc3",
   "metadata": {},
   "source": [
    "Für ein Gewicht $w_{jk}^{L-1}$, das zwischen dem Neuron $k$ in der Schicht $L-2$ und dem Neuron $j$ in der Schicht $L-1$ verbunden ist, oder einen Bias-Wert in der Schicht $L-1$ ergibt sich die Ableitung wie folgt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16d7f4d-be3d-446a-8016-cad736005573",
   "metadata": {},
   "source": [
    "$${\\frac {\\partial J} {\\partial w_{jk}^{L-1}}} = {\\frac {\\partial z_k^{L-1}} {\\partial w_{jk}^{L-1}}} {\\frac {\\partial J} {\\partial z_k^{L-1}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd203217-fb86-4f8a-8972-f6b252a4edf7",
   "metadata": {},
   "source": [
    "$${\\frac {\\partial J} {\\partial b_{k}^{L-1}}} = {\\frac {\\partial z_k^{L-1}} {\\partial b_{k}^{L-1}}} {\\frac {\\partial J} {\\partial z_k^{L-1}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a5afd-7f88-4b53-aba7-840faff6926c",
   "metadata": {},
   "source": [
    "Wie die Formeln zeigen, hängen die partiellen Ableitungen der Cost Function in Bezug auf die Gewichte, Bias-Werte und aktivierten Ausgaben stets von der partiellen Ableitung der Cost Function in Bezug auf die rohe Ausgabe ab. Dies gilt auch für die Gewichte und Bias-Werte in den vorherigen Schichten. Die Berechnung der partiellen Ableitung der Cost Function in Bezug auf die rohe Ausgabe wird später detaillierter erläutert. Zunächst behandle ich die Berechnung der partiellen Ableitungen der rohen Ausgaben $z$ in Bezug auf die Gewichte, Bias-Werte und aktivierten Ausgaben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162cd97-ea80-4ce4-987c-6fe62e107b59",
   "metadata": {},
   "source": [
    "Die Berechnung einer rohen Ausgabe $z_i^L$ kann durch folgende Formel dargestellt werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a229b-1522-45ee-b238-7cabd69303bd",
   "metadata": {},
   "source": [
    "$$z_j^L = \\sum_{k=1}^m {w_{jk}^L a_k^{L-1} + b_j^L}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d390d620-81ee-4efe-8b87-3ccb898b271b",
   "metadata": {},
   "source": [
    "Dabei bezeichnet $m$ die Anzahl an Neuronen in der Schicht $L-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a2e888-cb10-4ee9-b0d7-c8d7a42476e1",
   "metadata": {},
   "source": [
    "Aus dieser Formel lassen sich die partiellen Ableitungen der rohen Ausgabe nach den Gewichten, den aktivierten Ausgaben und den Bias-Werten ableiten:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ef66f-f1b5-4013-af16-b3e9a9b68dd0",
   "metadata": {},
   "source": [
    "$${\\frac  {\\partial z_j^L} {\\partial w_{jk}^L}} = a_k^{L-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390cf83f-206a-4acd-993c-6beabec2c1de",
   "metadata": {},
   "source": [
    "$${\\frac  {\\partial z_j^L} {\\partial b_{j}^L}} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb2af0-1dd3-44aa-a548-325859188ad4",
   "metadata": {},
   "source": [
    "$${\\frac  {\\partial z_j^L} {\\partial a_k^{L-1}}} = w_{jk}^L$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d039cf-1143-4ef2-822d-ae2d48fbb76b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die partielle Ableitung nach den Gewichten hängt von der aktivierten Ausgabe $a_k^{L-1}$ ab, die Ableitung nach den Bias-Werten ist konstant und entspricht eins. Die Ableitung nach den aktivierten Ausgaben ist wiederum durch das Gewicht $w_{jk}^L$ bestimmt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd212ed0-1359-43c6-9e44-725d3ffda554",
   "metadata": {},
   "source": [
    "Basierend auf diesen Formeln erweitere ich die Klasse \"Layer\" um die Methode \"backwards\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c6384-f634-4752-89b8-2e25cbdec906",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Layer(Layer):\n",
    "    def backwards(self, gradient_raw_outputs):\n",
    "        \"\"\"\n",
    "        gradient_raw_outputs: Gradient der Cost Function in Bezug zu den rohen Ausgaben der nächsten Schicht (dJ/dz)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Gradient der Cost Function in Bezug zu den Gewichte von der jeweiligen Schicht (dJ/dw)\n",
    "        self.gradient_weights = np.dot(self.saved_inputs.T, gradient_raw_outputs)\n",
    "\n",
    "        # Gradient in Bezug zu den Bias-Werten (dJ/db)\n",
    "        self.gradient_bias = np.sum(gradient_raw_outputs, axis=0, keepdims=True)\n",
    "\n",
    "        # Gradient  in Bezug zu den aktivierten Ausgaben (dJ/da)\n",
    "        gradient_activated_outputs = np.dot(gradient_raw_outputs, self.weights.T)\n",
    "        return gradient_activated_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353cc81-3669-4483-b4d5-f9159d352be7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die Methode \"backwards\" verwendet den Parameter \"gradient_raw_outputs\", der den Gradienten der Cost Function in Bezug auf die rohen Ausgaben darstellt. Anders ausgedrückt, handelt es sich dabei um den Vektor der partiellen Ableitungen der Cost Function bezüglich der rohen Ausgaben. Dieser Gradient wird genutzt, um die Gradienten der Cost Function in Bezug auf die Gewichte, Bias-Werte und aktivierten Ausgaben zu berechnen. Der Gradient in Bezug auf die aktivierten Ausgaben gebe ich für die Berechnung im kommenden Abschnitt aus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734254ac-62bb-4c27-a00b-3666afdb4b8d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Nun werde ich die partiellen Ableitungen der aktivierten Ausgaben in Bezug auf die rohen Ausgaben erklären. Als Beispiel verwende ich hierbei die ReLU Activation Function. Wie im Kapitel \"1.4.2 ReLU Function\" bereits erklärt, wird die ReLU-Funktion mathematisch wie folgt dargestellt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff1fb4-8d47-46af-9ea9-9c22ae2f3312",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$a_i=max(0,z_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb80d9d-b44f-449c-bb01-00a2fbcc9af4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die Ableitung der ReLU Function lautet demnach also:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65fe75e-1581-4481-a41c-1b3f8df16173",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$${\\frac d {dz_j} max(z_j,0)} = 1 (z_j \\gt 0)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8bbfcb-8804-443c-b32f-4dfab20be248",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die Änderungsrate ist also null, wenn die Eingabe negativ ist, und eins, wenn sie positiv ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099573b-76f1-45f5-a874-7b8bc3e8c217",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReLU(ReLU):\n",
    "    def backwards(self, gradient_activated_outputs):\n",
    "        \"\"\"\n",
    "        gradient_activated_outputs: Gradient der Cost Function in Bezug zu den den aktivierten Ausgaben (dJ/da)\n",
    "        \"\"\"\n",
    "        # Gradient der Cost Function in Bezug zu den rohen Ausgaben (dJ/dz)\n",
    "        gradient_raw_outputs = gradient_activated_outputs * (self.raw_outputs > 0)\n",
    "        return gradient_raw_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1a315-c35f-4c04-8285-511743bed160",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Basierend auf dieser Information erweitere ich auch die ReLU-Klasse mit der Methode \"backwards\". Diese Methode nimmt den Gradienten \"gradient_activated_outputs\" entgegen, der entweder von der Methode \"Layer.backwards\" oder direkt von der Cost Function berechnet wird. Mit diesem Gradienten wird der Gradient \"gradient_raw_outputs\", also der Gradient der Cost Function in Bezug auf die rohen Ausgaben, berechnet und anschließend zurückgegeben, um in der Methode \"Layer.backwards\" verwendet zu werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be58162c-7707-457d-876f-f8d4c3d73d1e",
   "metadata": {},
   "source": [
    "Anschließend fehlt noch die Ableitungen für den Categorical Cross Entropy und für die Softmax Activcation Function. Um die partielle Ableitung des Categorical Cross Entropy auf die rohe Ausgabe $z_{ij}$ für das $j$-te Neuron und für das $i$-te Trainingsbeispiel, kann folgende Formel verwendet werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e35dea-62b0-4b5a-b8fe-53f401058aad",
   "metadata": {},
   "source": [
    "$${\\frac {\\partial J} {\\partial z_{ij}}} = {\\frac {\\partial \\hat{y}_{ij}} {\\partial z_{ij}}} {\\frac {\\partial J} {\\partial \\hat{y}_{ij}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694a27f8-3d65-4140-ab6d-5ca9b3c28734",
   "metadata": {},
   "source": [
    "Anstatt die partiellen Ableitungen einzeln auszurechnen, können diese allerdings kombiniert werden um die Berechnungen effizienter zu machen. Die partielle Ableitung der Loss Function $L$ für das Trainingsbeispiel $i$ in Bezug zu den rohen Ausgabewerte $z$ wird berechnet, in dem der vorhergesagte Wert $\\hat{y}_{ij}$ für das Ausgabeneruons $j$ subtrahiert mit dem jeweiligen tatsächlichen Zielwert $y_{ij}$ wird. (vgl. ) Die Formel sieht demnach so aus:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ddc3d-dfbf-4ba0-93be-a1626edf20c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$${\\frac {\\partial L_i} {\\partial z_{ij}}} = {\\hat{y}_{ij} - y_{ij}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9aa9a8-acb5-456e-8198-893dbbd7a904",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "und somit ist die partielle Ableitung der gesamten Cost Function $J$ auf die rohen Ausgaben:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca26a2-d231-4453-8ba9-eb288d9ab5a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$${\\frac {\\partial J} {\\partial z_{ij}}} = {\\frac 1 N} \\sum_{i=1}^N \\hat{y}_{ij} - y_{ij}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a88d6f-805a-4f87-a8b9-5d4942e7277f",
   "metadata": {},
   "source": [
    "vereinfacht lässt sich schreiben:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9f125f-6b96-4fca-a62f-42b1fef62819",
   "metadata": {},
   "source": [
    "$${\\frac {\\partial J} {\\partial z_{ij}}} = {\\frac 1 N} (\\hat{y}_{ij} - y_{ij})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fbe4be-0f71-4a4f-974f-eb0544f1d820",
   "metadata": {},
   "source": [
    "Basierend darauf erweitere ich die Klassen \"CategoricalCrossEntropy\" und  \"Softmax\" ebenfalls mit den Methoden \"backwards\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8a3cf-5825-4fa5-afae-b122454666ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CategoricalCrossEntropy(CategoricalCrossEntropy):\n",
    "    def backwards(predictions, targets):\n",
    "        gradient_raw_outputs = (predictions - targets) / len(predictions)\n",
    "        return gradient_raw_outputs\n",
    "\n",
    "class Softmax(Softmax):\n",
    "    def backwards(self, gradient_raw_outputs):\n",
    "        # Gibt die Gradienten direkt weiter (Softmax wird in Kombination mit Kreuzentropie verwendet)\n",
    "        return gradient_raw_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a8010-6e61-427e-ac0c-00772d97c227",
   "metadata": {},
   "source": [
    "\"CategoricalCrossEntropy.backwards\" berechnet hierbei den Gradienten in Bezug zu den rohen Ausgaben \"gradient_raw_outputs\" und gibt diesen wieder. Da diese Berechnung mit Softmax kombiniert wurde, gibt \"Softmax.backwards\" diesen Gradienten ohne Modifizierung direkt aus. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0676b4-5524-41fd-98d3-d88d3fdeaf09",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Um die Backpropagation durchzuführen, erstelle ich für die Klasse \"Netzwerk\" eine neue Methode namens \"backpropagation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3452c6c4-edd6-4591-801b-d7b7d56ccc78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Network(Network):\n",
    "    def __init__(\n",
    "        self, cost_function\n",
    "    ):\n",
    "        self.layers = []\n",
    "        self.activation_functions = []\n",
    "        self.cost_function = cost_function\n",
    "    \n",
    "    def backpropagation(self, predictions, targets):\n",
    "        # Veränderung der vorhergesagten Ausgaben auf den Verlust (dC/da)\n",
    "        # Beim Categorical Cross Entropy + Softmax sind das die gradient_raw_outputs\n",
    "        gradient_activated_outputs = self.cost_function.backwards(predictions, targets)\n",
    "        # Rückwärts berechnet, von Ausgabeschicht zu Eingabeschicht\n",
    "        for layer, activation_function in zip(\n",
    "            reversed(self.layers), reversed(self.activation_functions)\n",
    "        ):\n",
    "            # Veränderung der rohen Ausgaben der aktuellen Schicht auf den Verlust) (dC/dz).\n",
    "            gradient_raw_outputs = activation_function.backwards(gradient_activated_outputs)\n",
    "\n",
    "            # Veränderung der Gewichte, es Bias-Werte und den aktivierten Ausgaben der vorherigen Schicht auf den Verlust) (dC/dW) (dC/db) (dC/da)\n",
    "            gradient_inputs = layer.backwards(gradient_raw_outputs)\n",
    "            gradient_activated_outputs = gradient_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd599e-9f1f-41e3-acb0-50522c8b2660",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Diese Methode berechnet zuerst den Gradienten der rohen Ausgabewerte der letzten Schicht und berechnet dann schichtweise rückwärts den Gradient der rohen Ausgaben mit \"aktivierung.rueckwaerts(gradient)\" und den Gradient der Gewichte, Bias-Werte und aktivierten Ausgaben mit \"schicht.rueckwaerts(gradient)\". Nachdem die Gradienten berechnet wurden, kann die Gewicht- und Bias-Werte-Aktualisierung durchgeführt werden, wie beschrieben in Kapitel \"2.3 Gradientenabstieg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8e09ca-40a7-4b73-a9b4-970246467a03",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Optimierungsfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b231afc-b7f5-4c57-87b4-56f0faa8cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GD(GD):\n",
    "    def train(\n",
    "        self,\n",
    "        inputs,\n",
    "        targets,\n",
    "        epochs,\n",
    "    ):\n",
    "        for _ in range(epochs):\n",
    "            # Vorwärtsdurchlauf: Berechnung der Vorhersagen\n",
    "            predictions = network.forward_propagation(inputs)\n",
    "\n",
    "            # Rückwärtsdurchlauf: Berechnung der Gradienten\n",
    "            network.backpropagation(predictions, targets)\n",
    "\n",
    "             # Aktualisiere Gewichte und Bias basierend auf den Gradienten\n",
    "            self.update_parameters()\n",
    "\n",
    "\n",
    "class SGD(GD):\n",
    "    def train(\n",
    "        self,\n",
    "        inputs,\n",
    "        targets,\n",
    "        epochs,\n",
    "    ):\n",
    "        for epoch in range(epochs):\n",
    "            for index in range(len(inputs)):                \n",
    "                # Vorwärtsdurchlauf: Berechnung der Vorhersagen\n",
    "                single_inputs = inputs[index : index + 1]\n",
    "                single_targets = targets[index : index + 1]\n",
    "                predictions = network.forward_propagation(single_inputs)\n",
    "    \n",
    "                # Rückwärtsdurchlauf: Berechnung der Gradienten\n",
    "                network.backpropagation(predictions, single_targets)\n",
    "    \n",
    "                 # Aktualisiere Gewichte und Bias basierend auf den Gradienten\n",
    "                self.update_parameters()\n",
    "\n",
    "class MiniBatchGD(GD):\n",
    "    def train(\n",
    "        self,\n",
    "        inputs,\n",
    "        targets,\n",
    "        epochs,\n",
    "        batch_size\n",
    "    ):\n",
    "        for epoch in range(epochs):\n",
    "            for start in range(0, len(inputs), batch_size):\n",
    "                batch_inputs = inputs[start : start + batch_size]\n",
    "                batch_targets = targets[start : start + batch_size]\n",
    "                \n",
    "                # Vorwärtsdurchlauf: Berechnung der Vorhersagen\n",
    "                predictions = network.forward_propagation(batch_inputs)\n",
    "    \n",
    "                # Rückwärtsdurchlauf: Berechnung der Gradienten\n",
    "                network.backpropagation(predictions, batch_targets)\n",
    "    \n",
    "                 # Aktualisiere Gewichte und Bias basierend auf den Gradienten\n",
    "                self.update_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105c5b1-f732-4cc5-8c35-66341f824739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from daten.lade_daten import lade_trainings_daten\n",
    "\n",
    "network = Network(CategoricalCrossEntropy)\n",
    "network.add_layer(\n",
    "    Layer(784, 20),  # Eingabeschicht → versteckte Schicht\n",
    "    ReLU(),  # Aktivierungsfunktion für die versteckte Schicht\n",
    ")\n",
    "network.add_layer(\n",
    "    Layer(20, 10),  # Versteckte Schicht → Ausgabeschicht\n",
    "    Softmax(),  # Aktivierungsfunktion für die Ausgabeschicht\n",
    ")\n",
    "\n",
    "def train_neural_network(network):\n",
    "    # Bilder (Eingabewerte) und labels (tatsächliche Zielwerte als Wahrscheinlichkeiten)\n",
    "     #gd = GD(network, 0.1)\n",
    "    #sgd = SGD(network, 0.01)\n",
    "    mini_batch_gd = MiniBatchGD(network, 0.05)\n",
    "    images, labels = lade_trainings_daten()\n",
    "    #gd.train(images, labels, 2)\n",
    "    #sgd.train(images, labels, 5)\n",
    "    mini_batch_gd.train(images, labels, 1, 32)\n",
    "\n",
    "train_neural_network(network)\n",
    "test_neural_network(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4184b-b7e8-48ba-aac6-d9688faa0805",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Genetische Algorithmen\n",
    "\n",
    "## Grundlagen\n",
    "\n",
    "Genetische Algorithmen sind eine Art von Optimierungsalgorithmen, die mit dem Prozess der Evolution vergleichbar sind. Genetische Algorithmen werden verwendet, um mithilfe von biologischen Prozessen wie Reproduktion und natürliche Selektion Lösungen zu Problemen zu finden. (vgl. Kanade, o.J.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb1180-64bf-40cf-83ab-221a79a2819f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Genetische Algorithmen eignen sich hervorragend für Probleme, bei denen aus einer großen Anzahl von Möglichkeiten Lösungen gefunden werden müssen. Außerdem können sie für die Lösung von kombinatorischen Problemen, bei denen eine optimale Anordnung von Elementen in einer begrenzten Liste gesucht wird, verwendet werden. (ebd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477df349-651f-419e-8019-72a4828cde4d",
   "metadata": {},
   "source": [
    "Eine einfache Anwendung für genetische Algorithmen ist das „Knapsack“-Problem. Bei diesem Problem ist ein Rucksack gegeben, in den man Gegenstände hineinlegen kann, die jeweils ein Gewicht und einen Geldwert besitzen. Ziel ist, dass der Rucksack eine möglichst hohe Summe an Geldwerten enthält, die nicht die Gewichtgrenze überschreitet. (vgl. Bhayani, o.J.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc678b6b-1152-4b94-8e17-638dec76ea03",
   "metadata": {},
   "source": [
    "Um die Funktionsweise von genetischen Algorithmen zu illustrieren, verwende ich die Programmiersprache Python, um das „Knapsack“-Problem zu lösen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505da58e-20a8-42f0-b75a-87022fbb0e10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Population\n",
    "\n",
    "Ein wichtiger Bestandteil von genetischen Algorithmen ist das Konzept einer Population, die eine Kollektion von Individuen darstellt. Ein Individuum repräsentiert dabei eine mögliche Lösung zu einem Problem.  (vgl. Kanade, o.J.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0aa55-d076-4071-9a5b-043d8d9bce16",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "class Item:\n",
    "    def __init__(self, name, mass, value):\n",
    "        self.name = name\n",
    "        self.mass = mass\n",
    "        self.value = value\n",
    "\n",
    "item_list = [\n",
    "    # Handy mit 3kg Masse und einem Geldwert von 5€\n",
    "    Item(\"Handy\", mass=3, value=5),\n",
    "    Item(\"Laptop\", 6, 10),\n",
    "    Item(\"Diamant\", 1, 30),\n",
    "    Item(\"Brot\", 1, 1)\n",
    "]\n",
    "\n",
    "class Individual:\n",
    "    def __init__(self, item_bits):\n",
    "        self.item_bits = item_bits\n",
    "\n",
    "    def print_items_in_backpack(self):\n",
    "        for item, is_in_backpack in zip(item_list, self.item_bits):\n",
    "            if is_in_backpack:\n",
    "                print(f\"Gegenstand: {item.name}, Masse: {item.mass}kg, Geldwert: {item.value}€\")\n",
    "\n",
    "individual = Individual([0, 1, 0, 1])\n",
    "\n",
    "individual.print_items_in_backpack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c31bf-ca29-45c1-a825-9d945106d7e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die Repräsentation eines Individuums stelle ich mit einer Liste von binären Zahlen dar. Ist die Zahl 0, dann ist der Gegenstand nicht im Rucksack. Ist die Zahl 1, dann ist er schon im Rucksack. Die Position des Gegenstandes sagt aus, um was für einen Gegenstand es sich handelt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8de92-9a54-4cea-aca7-734d13fb4ef6",
   "metadata": {},
   "source": [
    "Zur Modellierung eines eines Individuums erstelle ich die Klasse \"Individual\", deren Attribut \"item_bits\" diese Liste speichert. Die verfügbaren Gegenstände werden durch die Klasse \"Item\" erstellt. Jedes Objekt dieser Klasse beinhaltet einen Namen, eine Masse und einen Geldwert. Die Liste \"item_list\" enthält alle verfügbaren Gegenstände. Der erste Gegenstand in dieser Liste ist zum Beispiel ein Handy mit einer Masse von 3kg und einem Wert von €5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e234a-38a7-4e85-8351-5424b4b43528",
   "metadata": {},
   "source": [
    "Als Beispiel verwende ich das Individuum [0, 1, 0, 1]. Das bedeutet, dasss der Rucksack den Laptop und das Brot enthält. Das wird durch die Methode \"print_items_in_backpack\" veranschaulicht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432fa1c-8bb7-4e98-8337-9fccfe82ab7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Der Genetische Algorithmus startet mit einer initialen Population. Diese Population wird zufällig generiert und bildet durch Operatoren wie Selektion, Crossover und Mutation die Population in der nächsten Generation. Dieser Vorgang wird iterativ durchgeführt, um dann zu einer optimalen sowie effektiven Lösung zu kommen. Diese Operatoren spiegeln Prozesse wie natürliche Selektion, Reproduktion und genetische Variation in der Natur wider. (vgl. Kanade, o.J.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9d1a0-95da-454f-8643-015e8e4a488e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Individual(Individual):\n",
    "    def create_random_individual():\n",
    "        random_item_bits = []\n",
    "        for _ in item_list: # für jedes Element in der Gegenstände Liste\n",
    "            bit = random.choice([0, 1]) # zufällig 1 oder 0 wählen\n",
    "            random_item_bits.append(bit)\n",
    "        return Individual(random_item_bits)\n",
    "\n",
    "class Population:\n",
    "    def __init__(self, population_size):\n",
    "        self.population_size = population_size\n",
    "        self.create_initial_population()\n",
    "    \n",
    "    def create_initial_population(self):\n",
    "        self.population = []\n",
    "        while population_size > len(self.population):\n",
    "            individual = Individual.create_random_individual()\n",
    "            self.population.append(individual)\n",
    "\n",
    "    def print_population(self):\n",
    "        for individual in self.population:\n",
    "            print(individual.item_bits)\n",
    "\n",
    "population_size = 8\n",
    "population = Population(population_size)\n",
    "population.print_population()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584df810-bb79-4719-8910-f622fc0b41a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In diesem Code-Ausschnitt erzeuge ich eine Population von Individuen. Eine Population wird mit der Methode \"create_initial_population\" in der Klasse \"Population\" erstellt. Dabei werden Individuen mit einer zufälligen Sequenz von 0- und 1-Bits erzeugt, die die Gegenstände im Rucksack darstellen. Dies geschieht durch die statische Methode \"create_random_individual\" in der Klasse \"Individual\". Die Anzahl der Individuen in der Population wird durch das Attribut \"population_size\" festgelegt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e1ff46-3e05-42c4-989e-59950dc4ee21",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Fitness-Funktion\n",
    "\n",
    "Die „Fitness“-Funktion evaluiert, wie „fit“ ein Individuum oder wie gut eine mögliche Lösung in der Population ist. Um eine effektive Lösung zu einem Problem zu finden, ist es sehr wichtig, eine gute Fitness-Funktion zu kreieren. Eine schlechte Fitness-Funktion kann potenziell gute Lösungen als schlecht bewerten und schlechte Lösungen als gut und führt somit zu einer nicht effektiven Lösung für ein bestimmtes Problem. (vgl. Bhayani, o.J.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba02d29-817e-4714-b722-fcb9a7755bf8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "class Individual(Individual):    \n",
    "    def calculate_fitness(self, mass_limit):\n",
    "        total_mass = 0\n",
    "        total_value = 0\n",
    "        # Gehe jeden Gegenstand des Individuums durch\n",
    "        for item, is_in_backpack in zip(item_list, self.item_bits):\n",
    "            if is_in_backpack:\n",
    "                total_mass += item.mass\n",
    "                total_value += item.value\n",
    "\n",
    "        if total_mass > mass_limit:\n",
    "            self.fitness_value = 0\n",
    "            return\n",
    "\n",
    "        self.fitness_value = total_value\n",
    "\n",
    "\n",
    "class Population(Population):          \n",
    "    def calculate_fitness(self, mass_limit):\n",
    "        for individual in self.population:\n",
    "            individual.calculate_fitness(mass_limit)\n",
    "\n",
    "mass_limit = 5\n",
    "population = Population(population_size)\n",
    "population.calculate_fitness(mass_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a699c0-a50b-4797-ae6a-a52318422955",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Um den Fitness-Wert in meinem Programm zu berechnen, verwende ich die Methode \"calculate_fitness\". Der Fitness-Wert eines Individuum entspricht der Summe aller Geldwerte der Gegenstände, die sich im Rucksack befinden. Überschreitet allerdings das Gesamtgewicht der ausgewählten Gegenstände das Massenlimit (\"mass_limit\"), so hat ein Individuum einen Fitness-Wert von 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3817428-1cd2-4a41-ac28-9bcd04e964c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Genetische Operatoren\n",
    "\n",
    "### Selektion\n",
    "\n",
    "Um die Population der nächsten Generation zu bilden, werden Individuen aus der aktuellen Population genommen. Diese Individuen werden reproduziert, um dann Nachkommen zu generieren. Grundsätzlich sollen die besseren Individuen in die nächste Generation übergehen, in der Hoffnung, dass ihre Nachkommen noch besser werden. Es gibt mehrere Methoden, um diese Selektion durchzuführen. Eine Methode ist die „Tournament-Selektion“. Bei dieser Methode werden zwei Individuen zufällig ausgewählt und miteinander verglichen. Das Individuum mit dem höheren Fitness-Wert wird dann als Elternteil für die nachkommende Generation bestimmt. (vgl. Bhayani, o.J.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410ba4d-355d-4f51-b241-217ee956c507",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "def tournament(enemy1, enemy2):\n",
    "    if enemy1.fitness_value > enemy2.fitness_value:\n",
    "        return enemy1\n",
    "    else:\n",
    "        return enemy2\n",
    "\n",
    "def selection(population):\n",
    "    enemies = random.sample(population, 4) # 4 zufällige Individuuen\n",
    "    winner1 = tournament(enemies[0], enemies[1])\n",
    "    winner2 = tournament(enemies[2], enemies[3])\n",
    "    return [winner1, winner2]\n",
    "\n",
    "selection(population.population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc85fde-e980-4e62-bcee-73a78128ec1f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Bei meinem Programm werden vier Individuen aus der aktuellen Population zufällig ausgewählt. Die zwei Gewinner gehen zur nächsten Operation über. Der jeweilige Gewinner ist das Individuum, das den höheren Fitness-Wert besitzt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23337b77-2611-415a-8adb-79737d2a5eae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Kreuzung\n",
    "\n",
    "Kreuzung (\"Crossover\") ist ein Genetischer Operator, der zur Erzeugung neue Individuen basierend auf deren Eltern verwendet wird. Dabei werden die Gene der Eltern generiert, um Nachkommen zu bilden. Es gibt verschiedene Arten Methoden der Kreuzung, eine davon ist \"single-point crossover\". Bei dieser Methode wird ein Punkt innerhalb der Chromosomen ausgewählt, der die genetischen Informationen der Eltern in zwei Abschnitte aufteilt. Die Nachkommen erhalten den ersten Teil von einem Elternteil und den restliche Abschnitt vom anderen Elternteil. (vgl. Dutta, o.J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d994d2-f659-4bd5-9f33-19497e3eea54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crossover_parents(parent1, parent2):\n",
    "    bits_amount = len(parent1.item_bits)\n",
    "    half_amount = int(bits_amount / 2)\n",
    "\n",
    "    # Erste Hälfte von Elternteil 1 plus zweite Hälfte von Elternteil 2\n",
    "    child1_bits = parent1.item_bits[:half_amount] + parent2.item_bits[half_amount:]\n",
    "\n",
    "    # Erste Hälfte von Elternteil 2 plus zweite Hälfte von Elternteil 1\n",
    "    child2_bits = parent2.item_bits[:half_amount] + parent1.item_bits[half_amount:]\n",
    "\n",
    "    child1 = Individual(child1_bits)\n",
    "    child2 = Individual(child2_bits)\n",
    "    return (child1, child2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc5a86d-5c6a-4d00-bb41-3d14c6c41574",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die Funktion \"crossover_parents\" in meinem Code generiert neue Individuen indem sie die Bit-Sequenz der Eltern kombiniert. Dabei wird die erste Hälfte der Bits von einem Elternteil und die zweite Hälfte vom anderen übernommen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b8db5-e8b7-4c78-8da9-dd05757c6dac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Mutation\n",
    "\n",
    "Mutation ist ebenfalls ein Genetischer Operator und wird eingesetz, um die genetische Vielfalt innerhalb einer Population zu erhöhen. Es gibt verschiedene Mutationsmethoden, eine davon ist \"bit flip mutation\". Bei diesem Algorithmus werden zufällige Bits eines Individuums invertiert, das heißt, aus einer eins wird eine null und aus einer null eine eins. (vgl. Sil, o.J.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102f38a-496b-4c09-abe0-420b1501a67b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "def mutatate_child(individual):\n",
    "    bits_amount = len(individual.item_bits)\n",
    "    random_bit = random.randrange(bits_amount)\n",
    "    individual.item_bits[random_bit] = (\n",
    "        1 - individual.item_bits[random_bit]\n",
    "    )  # 1 wird zu null und umgekehrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136121d6-8f82-4d14-b071-3b6598dbf7e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Mein Code mutiert Nachkommen mit der Funktion \"mutatate_child\". Dabei wird ein zufälliges Bit ausgewählt und invertiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76ea2c-1011-4420-8c7d-54dc8db9bd1a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Elitismus\n",
    "\n",
    "Durch die zufällige Auswahl der Individuen kann es allerdings passieren, dass das beste Individuum nicht für die nächste Generation verwendet wird. Um das zu vermeiden, wird Elitismus eingesetzt. Dabei wandert das Individuum mit den höchsten Fitness-Wert direkt in nachkommende Generation über. (vgl. Mitchell, 1996, S. 126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59396b-50eb-476d-b8cb-96064c9bb355",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "class Population(Population):\n",
    "    def create_new_population(self):\n",
    "        new_population = []\n",
    "        best_individuals = self.population[0:2]\n",
    "        new_population.extend(best_individuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e658e0-cccb-4941-9513-adc7546bb447",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die Individuen in meiner Population werde ich später basierend auf ihren Fitness-Wert sortieren. Die ersten zwei Individuen in der Population sind dem nach die Besten. Diese werden dann in die neue Generation ohne genetischer Veränderung übernommen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc5a074-480a-43a9-8943-118d10e76d20",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Neue Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9d1b4-114b-482c-a3bf-997b80f51aba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "class Population(Population):\n",
    "    def create_new_population(self):\n",
    "        new_population = []\n",
    "        best_individuals = self.population[0:2]\n",
    "        new_population.extend(best_individuals)\n",
    "        while population_size > len(new_population):\n",
    "            parent1, parent2 = selection(self.population)\n",
    "\n",
    "            child1, child2 = crossover_parents(parent1, parent2)\n",
    "\n",
    "            mutatate_child(child1)\n",
    "            mutatate_child(child2)\n",
    "\n",
    "            new_population.append(child1)\n",
    "            new_population.append(child2)\n",
    "\n",
    "        return new_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2faebd-e70f-4e59-ae0f-8223daff6fec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Eine neue Generation bilde ich mit der Methode \"create_new_population\". Zuerst werden die besten zwei Individuen unverändert in die \"new_population\" kopiert. Danach wird eine Schleife ausgeführt. Innerhalb der Schleife werden zwei Partner durch Tournament-Selektion ausgesucht. Diese bilden mit Kreuzung Nachkommen. Diese Nachkommen werden mit \"mutatate_child\" mutiert und dann zur neuen Population hinzugefügt. Dieser Prozess wiederhollt sich, bis die gewünschte Populationsgröße erreicht ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a18588e-4ecf-4f72-86c5-dc348d94e921",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Finalisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b149f-1154-4b55-8d2b-e22c6907b0c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "class Population(Population):\n",
    "    def start(self, mass_limit):\n",
    "        self.calculate_fitness(mass_limit)\n",
    "        for _ in range(500):\n",
    "            self.population = self.create_new_population()\n",
    "            self.calculate_fitness(mass_limit)\n",
    "\n",
    "            self.population.sort(\n",
    "                reverse=True, key=lambda individual: individual.fitness_value\n",
    "            )\n",
    "\n",
    "            best_individual = self.population[0]\n",
    "\n",
    "        print(best_individual.fitness_value)\n",
    "        print(best_individual.item_bits)\n",
    "\n",
    "population_size = 20\n",
    "mass_limit = 3000\n",
    "Population(population_size).start(mass_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e49e517-acfe-4ed5-9cc3-fde952140859",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Um eine angenäherte Lösung für das Knapsack-Problem zu finden verwende ich die Methode \"start\". Diese berechnet zuerst den Fitness-Wert aller Individuen. In der Schleife wird Code für jede Generation ausgefürt. Zuerst wird die neue Population erstellt, dann werden die Fitness-Werte dessen Individuen berechnet, und dann werden die Individuen basierend auf ihrer Fitness-Wert sortiert für Elitismus. Diese Schleife läuft für 500 Generation und liefert anschließend ein Ergebnis zurück."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed62ed6-2598-4e5c-a45b-6fb482591102",
   "metadata": {},
   "source": [
    "# Fazit\n",
    "\n",
    "Blla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3560f032-defe-41d3-a018-eb28d7f01d43",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Literaturverzeichnis\n",
    "\n",
    "Alake, Richmond (o.J.): Loss Functions in Machine Learning Explained. https://www.datacamp.com/tutorial/loss-function-in-machine-learning [Zugriff: 31.01.2025]\n",
    "\n",
    "Anshumanm2fja (2024): What is Forward Propagation in Neural Networks? https://www.geeksforgeeks.org/what-is-forward-propagation-in-neural-networks/ [Zugriff: 16.10.2024]\n",
    "\n",
    "Belagatti, Pavan (2024): Understanding the Softmax Activation Function: A Comprehensive Guide. https://www.singlestore.com/blog/a-guide-to-softmax-activation-function/ [Zugriff: 01.02.2025]\n",
    "\n",
    "Bhayani, Arpit (o.J.): Genetic algorithm to solve the Knapsack Problem. https://arpitbhayani.me/blogs/genetic-knapsack/ [Zugriff: 16.12.2024]\n",
    "\n",
    "Dey, Suman (2019): Understanding Objective Functions in Deep Learning. https://dimensionless.in/understanding-objective-functions-in-deep-learning/ [Zugriff: 20.02.2025]\n",
    "\n",
    "Dutta, Avik (o.J.): Crossover in Genetic Algorithm. https://www.geeksforgeeks.org/crossover-in-genetic-algorithm/ [Zugriff: 10.02.2025]\n",
    "\n",
    "Gómez Bruballa, Raúl (2018): Understanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss and all those confusing names. https://gombru.github.io/2018/05/23/cross_entropy_loss/ [Zugriff: 02.02.2025]\n",
    "\n",
    "Kanade, Vijay (o.J.): What Are Genetic Algorithms? Working, Applications, and Examples. https://www.spiceworks.com/tech/artificial-intelligence/articles/what-are-genetic-algorithms/ [Zugriff: 16.12.2024]\n",
    "\n",
    "Khan, Azim (2024) A Beginner’s Guide to Deep Learning with MNIST Dataset. https://medium.com/@azimkhan8018/a-beginners-guide-to-deep-learning-with-mnist-dataset-0894f7183344 [Zugriff: 14.01.2025]\n",
    "\n",
    "Kinsley, Harrison (2020) Neural Networks from Scratch - P.4 Batches, Layers, and Objects. https://www.youtube.com/watch?v=TEWy9vZcxW4 [Zugriff: 16.10.2024]\n",
    "\n",
    "Kinsley, Harrison (2020): Neural Networks from Scratch - P.5 Hidden Layer Activation Functions. https://www.youtube.com/watch?v=gmjzbpSVY1A [Zugriff: 16.10.2024]\n",
    "\n",
    "Kostadinov, Simeon (2019): Understanding Backpropagation Algorithm. https://medium.com/towards-data-science/understanding-backpropagation-algorithm-7bb3aa2f95fd [Zugriff: 11.02.2025]\n",
    "\n",
    "Lheureux, Adil (o.J.): Feed-forward vs feedback neural networks. https://www.digitalocean.com/community/tutorials/feed-forward-vs-feedback-neural-networks [Zugriff: 16.10.2024]\n",
    "\n",
    "Lodhi Ramlakhan (o.J.): Difference between Shallow and Deep Neural Networks. https://www.geeksforgeeks.org/difference-between-shallow-and-deep-neural-networks/ [Zugriff: 31.01.2025]\n",
    "\n",
    "Muns, Andy (o.J.): Objective function types: A machine learning guide. https://telnyx.com/learn-ai/objective-function-machine-learning [Zugriff: 20.02.2025]\n",
    "\n",
    "Mitchell, Melanie (1996): An Introduction to Genetic Algorithms. Fifth printing. Cambridge, Massachusetts: The MIT Press.\n",
    "\n",
    "Nielsen, Michael (2015): Neural Networks and Deep Learning. http://neuralnetworksanddeeplearning.com/chap1.html [Zugriff: 16.10.2024]\n",
    "\n",
    "Saxena, Abhimanyu (2024): Classification vs Regression in Machine Learning. https://www.appliedaicourse.com/blog/classification-vs-regression-in-machine-learning/ [Zugriff: 01.02.2025]\n",
    "\n",
    "Sil, Pritam (o.J.): Mutation Algorithms for String Manipulation (GA). https://www.geeksforgeeks.org/mutation-algorithms-for-string-manipulation-ga/ [Zugriff: 10.02.2025]\n",
    "\n",
    "Singh, Abhay (2025): Gradient Descent Explained: The Engine Behind AI Training. https://medium.com/@abhaysingh71711/gradient-descent-explained-the-engine-behind-ai-training-2d8ef6ecad6f [Zugriff: 03.02.2025]\n",
    "\n",
    "Topper, Noah (2023): Sigmoid Activation Function: An Introduction. https://builtin.com/machine-learning/sigmoid-activation-function [Zugriff: 14.01.2025]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36008f25-3f63-4cb5-bef5-05645c2747fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div id=\"abb\"></div>"
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {},
   "style": "aba-format-osterreich.csl"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "number_sections": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
